tcp和udp的区别，tcp是怎么做错误处理的?
1. 基于连接vs无连接:
UDP是无连接的协议，和点对点连接之前不需要发送消息。这就是为什么，UDP更加适合消息的多播发布，从单个点向多个点传输消息。

2. 可靠性不同

3.有序性
TCP也保证了消息的有序性。该消息将以从服务器端发出的同样的顺序发送到客户端，尽管这些消息到网络的另一端时可能是无序的。TCP协议将会为你排好序。UDP不提供任何有序性或序列性的保证。数据包将以任何可能的顺序到达。

4.数据边界
TCP不保存数据的边界，而UDP保证。在传输控制协议，数据以字节流的形式发送，并没有明显的标志表明传输信号消息（段）的边界。

5.速度
TCP速度比较慢，而UDP速度比较快，因为TCP必须创建连接，以保证消息的可靠交付和有序性，他需要做比UDP多的多的事。

6.重量级vs轻量级
TCP被认为是重量级的协议，而与之相比，UDP协议则是一个轻量级的协议。因为UDP传输的信息中不承担任何间接创造连接，保证交货或秩序的的信息。这也反映在用于承载元数据的头的大小。

7. 头大小
TCP具有比UDP更大的头。一个TCP数据包报头的大小是20字节，UDP数据报报头是8个字节。TCP报头中包含序列号，ACK号，数据偏移量，保留，控制位，窗口，紧急指针，可选项，填充项，校验位，源端口和目的端口。而UDP报头只包含长度，源端口号，目的端口，和校验和

8. 拥塞或流控制
TCP有流量控制。在任何用户数据可以被发送之前，TCP需要三数据包来设置一个套接字连接。TCP处理的可靠性和拥塞控制。另一方面，UDP不能进行流量控制。

==============================================================================

流量控制和拥塞控制的实现机制：
1）TCP采用大小可变的滑动窗口机制实现流量控制功能。窗口的大小是字节。在TCP报文段首部的窗口字段写入的数值就是当前给对方设置发送窗口的数据的上限。
在数据传输过程中，TCP提供了一种基于滑动窗口协议的流量控制机制，用接收端接收能力（缓冲区的容量）的大小来控制发送端发送的数据量。
2）采用滑动窗口机制还可对网络进行拥塞控制，将网络中的分组（TCP报文段作为其数据部分）数量维持在一定的数量之下，当超过该数值时，网络的性能会急剧恶化。传输层的拥塞控制有慢开始（Slow-Start）、拥塞避免（Congestion Avoidance）、快重传（Fast Retransmit）和快恢复（Fast Recovery）四种算法。
拥塞：　大量数据报涌入同一交换节点（如路由器），导致该节点资源耗尽而必须丢弃后面到达的数据报时，就是拥塞。

==============================================================================

重传机制：
TCP每发送一个报文段，就设置一次定时器。只要定时器设置的重发时间到而还没有收到确认，就要重发这一报文段。 
TCP环境
报文往返时间不定、有很大差别
A、B在一个局域网络，往返时延很小
A、C在一个互联网内，往返时延很大
因此，A很难确定一个固定的、与B、C通信都适用的定时器时间
TCP采用了一种自适应算法。这种算法记录每一个报文段发出的时间，以及收到相应的确认报文段的时间。这两个时间之差就是报文段的往返时延。将各个报文段的往返时延样本加权平均，就得出报文段的平均往返时延T。

==============================================================================

滑动窗口机制：
TCP 采用大小可变的滑动窗口进行流量控制。窗口大小的单位是字节。
在 TCP 报文段首部的窗口字段写入的数值就是当前给对方设置的发送窗口数值的上限。发送窗口在连接建立时由双方商定。但在通信的过程中，接收端可根据自己的资源情况，随时动态地调整对方的发送窗口上限值(可增大或减小)。

==============================================================================

TIME_WAIT状态产生场景\理由\如何避免:

1. 主动关闭的Socket端会进入TIME_WAIT状态，并且持续2MSL时间长度，MSL就是maximum segment lifetime(最大分节生命期）；
这是一个IP数据包能在互联网上生存的最长时间，超过这个时间将在网络中消失。
MSL在RFC 1122上建议是2分钟，而源自berkeley的TCP实现传统上使用30秒，因而，TIME_WAIT状态一般维持在1-4分钟。

2. 主动关闭的一方在发送最后一个ack 后就会进入TIME_WAIT 状态 停留2MSL（max segment lifetime）时间这个是TCP/IP必不可少的，也就是“解决”不了的。

3. TIME_WAIT状态存在的理由：
    1）防止上一次连接中的包，迷路后重新出现，影响新连接
    （经过2MSL，上一次连接中所有的重复包都会消失）
    2）可靠的关闭TCP连接
        在进行关闭连接四路握手协议时，最后的ACK是由主动关闭端发出的，如果这个最终的ACK丢失，服务器将重发最终的FIN，因此客户端必须维护状态信息允 许它重发最终的ACK。
    如果不维持这个状态信息，那么客户端将响应RST分节，服务器将此分节解释成一个错误（在java中会抛出connection reset的SocketException)。
     因而，要实现TCP全双工连接的正常终止，必须处理终止序列四个分节中任何一个分节的丢失情况，主动关闭 的客户端必须维持状态信息进入TIME_WAIT状态

4.time_wait状态如何避免
首先服务器可以设置SO_REUSEADDR套接字选项来通知内核，如果端口忙，当TCP连接位于TIME_WAIT状态时可以重用端口。在一个非常有用的场景就是，如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时SO_REUSEADDR选项就可以避免TIME_WAIT状态。

==============================================================================

tcp连接建立的时候3次握手的具体过程，以及每一步原因：

（1）第一步：源主机A的TCP向主机B发出连接请求报文段，其首部中的SYN(同步)标志位应置为1，表示想与目标主机B进行通信，并发送一个同步序列号X(例：SEQ=100)进行同步，表明在后面传送数据时的第一个数据字节的序号是X＋1（即101）。SYN同步报文会指明客户端使用的端口以及TCP连接的初始序号。

（2）第二步：目标主机B的TCP收到连接请求报文段后，如同意，则发回确认。在确认报中应将ACK位和SYN位置1，表示客户端的请求被接受。确认号应为X＋1(图中为101)，同时也为自己选择一个序号Y。

（3）第三步：源主机A的TCP收到目标主机B的确认后要向目标主机B给出确认，其ACK置1，确认号为Y＋1，而自己的序号为X＋1。TCP的标准规定，SYN置1的报文段要消耗掉一个序号。

运行客户进程的源主机A的TCP通知上层应用进程，连接已经建立。当源主机A向目标主机B发送第一个数据报文段时，其序号仍为X＋1，因为前一个确认报文段并不消耗序号。
当运行服务进程的目标主机B的TCP收到源主机A的确认后，也通知其上层应用进程，连接已经建立。至此建立了一个全双工的连接。

==============================================================================

TCP初始化序列号不能设置为一个固定值，因为这样容易被攻击者猜出后续序列号，从而遭到攻击。

RFC1948中提出了一个较好的初始化序列号ISN随机生成算法。

ISN = M + F(localhost, localport, remotehost, remoteport).

M是一个计时器，这个计时器每隔4毫秒加1。

F是一个Hash算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值。
要保证hash算法不能被外部轻易推算得出，用MD5算法是一个比较好的选择。

==============================================================================

tcp断开连接的具体过程，其中每一步是为什么那么做：

1)第一步：源主机A的应用进程先向其TCP发出连接释放请求，并且不再发送数据。TCP通知对方要释放从A到B这个方向的连接，将发往主机B的TCP报文段首部的终止比特FIN置1，其序号X等于前面已传送过的数据的最后一个字节的序号加1。

2)第二步：目标主机B的TCP收到释放连接通知后即发出确认，其序号为Y，确认号为X＋1，同时通知高层应用进程，这样，从A到B的连接就释放了，连接处于半关闭状态，相当于主机A向主机B说：“我已经没有数据要发送了。但如果还发送数据，我仍接收。”此后，主机B不再接收主机A发来的数据。但若主机B还有一些数据要发送主机A，则可以继续发送。主机A只要正确收到数据，仍应向主机B发送确认。

3)第三步：若主机B不再向主机A发送数据，其应用进程就通知TCP释放连接。主机B发出的连接释放报文段必须将终止比特FIN和确认比特ACK置1，并使其序号仍为Y，但还必须重复上次已发送过的ACK＝X＋1。

4) 第四步：主机A必须对此发出确认，将ACK置1，ACK＝Y＋1，而自己的序号是X＋1。这样才把从B到A的反方向的连接释放掉。主机A的TCP再向其应用进程报告，整个连接已经全部释放。

==============================================================================

tcp建立连接和断开连接的各种过程中的状态转换细节：

客户端：主动打开SYN_SENT--->ESTABLISHED--->主动关闭FIN_WAIT_1--->FIN_WAIT_2--->TIME_WAIT

服务器端：LISTEN（被动打开）--->SYN_RCVD--->ESTABLISHED--->CLOSE_WAIT(被动关闭)--->LAST_ACK--->CLOSED

其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。

==============================================================================

syn  flood是一种常见的DOS（denial of service拒绝服务）和Ddos(distributed denial of serivce 分布式拒绝服务）攻击方式。这是一种使用TCP协议缺陷，发送大量的伪造的TCP连接请求，使得被攻击方cpu或内存资源耗尽，最终导致被攻击方无法提供正常的服务。

　　要明白这种攻击原理，还要从TCP连接的建立说起：

　　大家都知道，TCP和UDP不同，它提供一种基于连接的，可靠的字节流服务。想要通信的双方，都要首先建立一条TCP连接。这条连接的两端只有通信的双方。TCP连接的建立是这样的：
　　首先，请求端（发送端）会发一个带有SYN标志位的报文，该报文中含有发送端的初始序号ISN（initinal sequence number)和发送端使用的端口号，该报文就是请求建立连接，
　　其次，服务器收到这个请求报文后，就会回一个SYN+ACK的报文，同时这个报文中也包含服务器的ISN以及对请求端的确认序号，这个确认序号的值是请求端的序号值+1，表示请求端的请求被接受，
　　最后，请求端收到这个报文后，就会回应给服务器一个ACK报文，到此一个TCP连接就建立了。

　　上面也就是典型的TCP三次握手过程（Three-way  Handshake)。问题就是在这最后一次的确认里，如果请求端由于某种异常（死机或掉线），服务器没有收到请求端发送的回应ACK。那么第三次握手没有完成，服务器就会向请求端再次发送一个SYN+ACK报文，并等待一段时间后丢弃这个未完成的连接。这个时间长度称为SYN Timeout，一般来说是分钟的数量级（大约30秒到2分钟）；
一个用户出现异常导致服务器等待一分钟是没有什么问题的。如果有恶意攻击者采用这种方式，控制大量的肉鸡来模拟这种情况，服务器端就要去维护一个大量的半连接表而消耗大量的cpu和内存资源。服务器会对这个半连接表进行一个遍历，然后尝试发送SYN+ACK来继续TCP连接的建立。实际上如果客户的TCP协议栈如果不够强大，最后的结果是服务器堆栈溢出崩溃。即使服务器端足够的强大，服务器也会因为忙于处理攻击者的TCP连接请求而无瑕理会正常的客户的请求，此时从客户端来看，服务器就已经失去响应，这时我们称做服务器遭受了SYN Flood攻击。

==============================================================================
send函数缓存问题
send()函数默认情况下会使用Nagle算法。Nagle算法通过将未确认的数据存入缓冲区直到积攒到一定数量一起发送的方法。来降低主机发送零碎小数据包的数目。所以假设send()函数发送数据过快的话，该算法会将一些数据打包后统一发出去。假设不了解这样的情况，接收端採会遇到看似非常奇怪的问题，比方成功recv()的次数与成功send()的次数不相等。在这中情况下，接收端能够通过recv()的返回值是否为0来推断发送端是否发送完成。

==============================================================================
Nagle算法：
是为了减少广域网的小分组数目，从而减小网络拥塞的出现；
该算法要求一个tcp连接上最多只能有一个未被确认的未完成的小分组，在该分组ack到达之前不能发送其他的小分组，tcp需要收集这些少量的分组，并在ack到来时以一个分组的方式发送出去；其中小分组的定义是小于MSS的任何分组；
该算法的优越之处在于它是自适应的，确认到达的越快，数据也就发哦送的越快；而在希望减少微小分组数目的低速广域网上，则会发送更少的分组；

设计规则如下：

　　（1）如果包长度达到最大报文长度（MSS，Maximum Segment Size），则允许发送；

　　（2）如果该包含有FIN，则允许发送；

　　（3）设置了TCP_NODELAY选项，则允许发送；

　　（4）未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送；

　　（5）上述条件都未满足，但发生了超时（一般为200ms），则立即发送。


关闭Nagle：
setsockopt(fd,IPPROTO_TCP,TCP_NODELAY,(char*)&flag,sizeof(flag));

==============================================================================
延迟ACK：
如果tcp对每个数据包都发送一个ack确认，那么只是一个单独的数据包为了发送一个ack代价比较高，所以tcp会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ack，如果在延迟ack定时器触发时候，发现ack尚未发送，则立即单独发送；
延迟ACK好处：
(1) 避免糊涂窗口综合症；
(2) 发送数据的时候将ack捎带发送，不必单独发送ack；
(3) 如果延迟时间内有多个数据段到达，那么允许协议栈发送一个ack确认多个报文段；

==============================================================================
当Nagle遇上延迟ACK：
试想如下典型操作，写-写-读，即通过多个写小片数据向对端发送单个逻辑的操作，两次写数据长度小于MSS，当第一次写数据到达对端后，对端延迟ack，不发送ack，而本端因为要发送的数据长度小于MSS，所以nagle算法起作用，数据并不会立即发送，而是等待对端发送的第一次数据确认ack；这样的情况下，需要等待对端超时发送ack，然后本段才能发送第二次写的数据，从而造成延迟；

由于有Nagle算法，如果发送端启用了Nagle算法，接收端启用了TCP Delayed Acknowledge。当发送端发起两次写一次读的时候，第一次写，由于TCP没有等待ACK，直接发出去了，而第二次写的时候，第一次写的ACK还没有接收到，从而等待；而接收端有Delayed Acknowledge机制，会等待40ms以提供合并多个ACK的机会。Nagle算法的使用在一些实时性要求比较高的场合，会引起一些问题。比如项目中设计的UI鼠标远程控制远端的机器时，发现远端的鼠标操作很卡顿，这是因为鼠标消息的发送端由于Nagle算法的默认开启，是有延迟的，

==============================================================================
如下场景考虑关闭Nagle算法：
(1) 对端不向本端发送数据，并且对延时比较敏感的操作；这种操作没法捎带ack；
(2) 如上写-写-读操作；对于此种情况，优先使用其他方式，而不是关闭Nagle算法：
--使用writev，而不是两次调用write，单个writev调用会使tcp输出一次而不是两次，只产生一个tcp分节，这是首选方法；
--把两次写操作的数据复制到单个缓冲区，然后对缓冲区调用一次write；
--关闭Nagle算法，调用write两次；有损于网络，通常不考虑；
setsockopt(fd,IPPROTO_TCP,TCP_NODELAY,(char*)&flag,sizeof(flag));

==============================================================================

epoll与select的区别：

问题的引出，当需要读两个以上的I/O的时候，如果使用阻塞式的I/O，那么可能长时间的阻塞在一个描述符上面，另外的描述符虽然有数据但是不能读出来，这样实时性不能满足要求，大概的解决方案有以下几种：

1.使用多进程或者多线程，但是这种方法会造成程序的复杂，而且对与进程与线程的创建维护也需要很多的开销。（Apache服务器是用的子进程的方式，优点可以隔离用户）

2.用一个进程，但是使用非阻塞的I/O读取数据，当一个I/O不可读的时候立刻返回，检查下一个是否可读，这种形式的循环为轮询（polling），这种方法比较浪费CPU时间，因为大多数时间是不可读，但是仍花费时间不断反复执行read系统调用。

3.异步I/O（asynchronous I/O），当一个描述符准备好的时候用一个信号告诉进程，但是由于信号个数有限，多个描述符时不适用。

4.一种较好的方式为I/O多路转接（I/O multiplexing）（貌似也翻译多路复用），先构造一张有关描述符的列表（epoll中为队列），然后调用一个函数，直到这些描述符中的一个准备好时才返回，返回时告诉进程哪些I/O就绪。select和epoll这两个机制都是多路I/O机制的解决方案，select为POSIX标准中的，而epoll为Linux所特有的。

区别（epoll相对select优点）主要有三：

1.select的句柄数目受限，在linux/posix_types.h头文件有这样的声明：#define __FD_SETSIZE    1024  表示select最多同时监听1024个fd。而epoll没有，它的限制是最大的打开文件句柄数目。

2.epoll的最大好处是不会随着FD的数目增长而降低效率，在selec中采用轮询处理，其中的数据结构类似一个数组的数据结构，而epoll是维护一个队列，直接看队列是不是空就可以了。epoll只会对"活跃"的socket进行操作---这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有"活跃"的socket才会主动的去调用 callback函数（把这个句柄加入队列），其他idle状态句柄则不会，在这点上，epoll实现了一个"伪"AIO。但是如果绝大部分的I/O都是“活跃的”，每个I/O端口使用率很高的话，epoll效率不一定比select高（可能是要维护队列复杂）。

3.使用mmap加速内核与用户空间的消息传递。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的。

==============================================================================
epoll中et和lt的区别与实现原理：

epoll有2种工作方式:LT和ET。
LT(level triggered 水平触发)是缺省的工作方式，并且同时支持block和no-block socket。
在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。
如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。
传统的select/poll都是这种模型的代表。

ET (edge-triggered 边缘触发)是高速工作方式，只支持no-block socket。
在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。
然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述 符发送更多的就绪通知，直到你做了某些操作
导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致 了一个
EWOULDBLOCK 错误）。
但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only 
once),不过在TCP协议中，ET模式的加速效用仍需要更多的benchmark确认。

epoll只有epoll_create,epoll_ctl,epoll_wait 3个系统调用。

==============================================================================
IP头：
版本号 4bit 0100(ipv4) 0110(ipv6)
首部长度 4bit 4字节为单位最小为5，最大为15
服务类型 8bit
数据报长度 16bit
ID号    16bit
分段标志 3bit
分段偏移 13bit
生存期TTL 8bit
协议号   8bit ICMP=1 TCP=16 UDP=7 OSPF=89
校验和   16bit
源IP    32bit
目的IP  32bit

TCP头：
源端口 16bit
目的端口 16bit
seq num 32bit
ack num 32bit
首部长度  4bit
保留位    6bit
TCP标志位 6bit
窗口大小  16bit
校验和    16bit
紧急指针  16bit
选项字段
数据字段
TCP头部最小20字节，最大60字节
TCP头部中没有包长度字段，因为TCP是流协议，没有流量边界
TCP有自己的流量拥塞控制算法，且依靠IP层分片

ARP头：
目的mac地址 6字节
源mac地址  6字节
类型      2字节 0x0800 IP报文 / 0x0806 ARP报文 / 0x8035 RARP报文
校验和     4字节
以太网最小帧长64字节

UDP头：
源端口 16bit
目的端口 16bit
用户数据报长度 16bit
校验和 16bit
数据字段
UDP头最小8字节

==============================================================================
FTP协议：
端口20 传送文件数据
端口21 传送控制指令，如连接请求等

SNMP协议：
端口161 管理进程获取SNMP代理数据
端口162 SNMP代理主动向管理进程发送数据

DNS协议：
TCP协议 端口53 DNS区域文件传送
UDP协议 端口53 域名解析服务

RIP协议：距离矢量协议
UDP 端口520 RIPv1使用广播进行邻居 RIPv2使用组播224.0.0.9进行路由表更新

OSPF协议：
协议号89, 全部路由器 224.0.0.5 DR路由器 224.0.0.6

BGP协议：
TCP 端口号179

