==============================================================================

同步和异步
同步就是烧开水，需要自己去轮询（每隔一段时间去看看水开了没），异步就是水开了，然后水壶会通知你水已经开了，你可以回来处理这些开水了。
同步和异步是相对于操作结果来说，会不会等待结果返回。
阻塞和非阻塞
阻塞就是说在煮水的过程中，你不可以去干其他的事情，非阻塞就是在同样的情况下，可以同时去干其他的事情。阻塞和非阻塞是相对于线程是否被阻塞。
其实，这两者存在本质的区别，它们的修饰对象是不同的。阻塞和非阻塞是指进程访问的数据如果尚未就绪，进程是否需要等待，简单说这相当于函数内部的实现区别，也就是未就绪时是直接返回还是等待就绪。
而同步和异步是指访问数据的机制,同步一般指主动请求并等待I/O操作完毕的方式,当数据就绪后在读写的时候必须阻塞,异步则指主动请求数据后便可以继续处理其它任务,随后等待I/O,操作完毕的通知,这可以使进程在数据读写时也不阻塞。

==============================================================================

网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。对于一次IO访问，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间，所以一般会经历两个阶段：
等待所有数据都准备好或者一直在等待数据，有数据的时候将数据拷贝到系统内核；
将内核缓存中数据拷贝到用户进程中；
对于socket流而言：
等待网络上的数据分组到达，然后被复制到内核的某个缓冲区；

把数据从内核缓冲区复制到应用进程缓冲区中；
https://www.cnblogs.com/George1994/p/6702084.html

==============================================================================

进程间通信方式：
管道 信号 共享内存 socket 消息队列 信号量

==============================================================================

1.管道（pipe）及有名管道（named pipe）：
管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。
管道是单向的、先进先出的、无结构的、固定大小的字节流，它把一个进程的标准输出和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的道端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。

==============================================================================

2.信号（signal）：
信号是在软件层次上对中断机制的一种模拟，它是比较复杂的通信方式，用于通知进程有某事件发生，一个进程收到一个信号与处理器收到一个中断请求效果上可以说是一致的。
信号是在软件层次上对中断机制的一种模拟，是一种异步通信方式。
SIGINT：在键盘按下<Ctrl+C>组合键后产生，默认动作为终止进程
SIGQUIT：在键盘按下<Ctrl+\>组合键后产生，默认动作为终止进程
SIGKILL：无条件终止进程。本信号不能被忽略、处理和阻塞。默认动作为终止进程。
它向系统管理员提供了一种可以杀死任何进程的方法
SIGALRM：定时器超时，超时的时间由系统调用alarm设置。默认动作为终止进程
SIGCHLD：子进程结束时，父进程会收到这个信号。默认动作为忽略该信号

程序可以用signal库函数来处理信号，它的定义如下:
#include <signal.h>
void (*signal(int sig, void (*func)(int)))(int);
signal函数作用是绑定信号值为sig的信号的响应时间为func指向的函数，即当捕获到sig信号时，调用func指向的函数(可称为信号处理函数)，另外func也可以用下面两个特殊值之一来代替信号处理函数：
SIG_IGN    忽略信号
SIG_DFL    恢复默认行为

信号种类
把那些建立在早期机制上的信号叫做"不可靠信号"，信号值小于SIGRTMIN(Red hat 7.2中，SIGRTMIN=32，SIGRTMAX=63)的信号都是不可靠信号。
进程每次处理信号后，就将对信号的响应设置为默认动作。在某些情况下，将导致对信号的错误处理；因此，用户如果不希望这样的操作，那么就要在信号处理函数结尾再一次调用signal()，重新安装该信号。

信号可能丢失，后面将对此详细阐述。 如果在进程对某个信号进行处理时，这个信号发生多次，对后到来的这类信号不排队，那么仅传送该信号一次，即发生了信号丢失。

Linux支持不可靠信号，但是对不可靠信号机制做了改进：在调用完信号处理函数后，不必重新调用该信号的安装函数（信号安装函数是在可靠机制上的实现）。因此，Linux下的不可靠信号问题主要指的是信号可能丢失。

信号值位于SIGRTMIN和SIGRTMAX之间的信号都是可靠信号，可靠信号克服了信号可能丢失的问题。
1 ~ 31的信号为传统UNIX支持的信号，是不可靠信号(非实时的)，后32个信号表示实时信号，等同于前面阐述的可靠信号。
非实时信号都不支持排队，都是不可靠信号；实时信号都支持排队，都是可靠信号。

不可靠信号是信号值小于SIGRTMIN的信号。信号的可靠与不可靠只与信号值有关，与信号的发送及安装函数无关。目前linux中的signal()是通过sigation()函数实现的，因此，即使通过signal（）安装的信号，在信号处理函数的结尾也不必再调用一次信号安装函数。同时，由signal()安装的实时信号支持排队，同样不会丢失。

后32个信号表示实时信号，等同于前面阐述的可靠信号。这保证了发送的多个实时信号都被接收。

信号的产生
1)由硬件产生，如从键盘输入Ctrl+C可以终止当前进程
2)由其他进程发送，如可在shell进程下，使用命令 kill -信号标号 PID，向指定进程发送信号。
3)异常，进程异常时会发送信号

信号的处理
发送信号的主要函数有：kill()、raise()、 sigqueue()、alarm()、setitimer()以及abort()。
信号是由操作系统来处理的，说明信号的处理在内核态。
信号不一定会立即被处理，此时会储存在信号的信号表中。
可以用kill命令给某个进程发送信号，如果不明确指定信号则发送SIGTERM信号，该信号的默认处理动作是终止进程。

阻塞信号
原型：
int sigprocmask(int how,const sigset_t *set,sigset_t *oset);
how:设置block阻塞表的方式
a.SIG_BLOCK:将信号集添加到block表中
b.SIG_UNBLOCK:将信号集从block表中删除
c.SIG_SETMASK：将信号集设置为block表
set:要设置的集合
oset:设置前保存之前block表信息
如果该进程当前并未处于执行态，则该信号就由内核保存起来，直到该进程恢复执行再传递个它；如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞取消时才被传递给进程。

获取未决信号
前面已经讲过，阻塞的信号处于未决的状态，会放入进程的未决信号表。
原型：
int sigpending(sigset_t *set);
set:out型参数，会将获得的当前进程的pending未决表中的信号集传入。

==============================================================================

3.消息队列（message queue）：
所谓消息队列，其实就是消息(数据)传输过程中保存的容器
消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息。

匿名管道以及命名管道是随进程的，进程的退出，意味着管道生命周期的结束；
其次，管道传送数据时以无格式字节流的形式传送，这有时会给程序的开发带来不便；
再者，担当数据传送媒介的管道，其缓冲区的大小也有较大的限制。
较管道来说，消息队列的生命周期更加持久。消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。 
消息队列是基于消息的， 而管道是基于字节流的，且消息队列的读取不一定是先入先出。消息队列与命名管道有一 样的不足，就是每个消息的最大长度是有上限的（MSGMAX），每个消息队列的总的字节数是有上限的（MSGMNB），系统上消息队列的总数也有一个上限（MSGMNI）
消息队列的数据结构（struct ipc_ids msg_ids）位于内核中，系统中的所有消息队列都可以在结构msg_ids中找到访问入口。 
消息队列就是一个消息的链表。
每个消息队列都有一个队列头，用结构struct msg_queue来描述。
队列头中包含了该消息队列的大量信息，包括消息队列键值、用户ID、组ID、消息队列中消息数目等等，甚至记录了最近对消息队列读写进程的ID。
读者可以访问这些信息，也可以设置其中的某些信息。

接受消息的时候
msgtyp等于0，则返回队列的最早的一个消息。
msgtyp大于0，则返回其类型为mtype的第一个消息。
msgtyp小于0，则返回其类型小于或等于mtype参数的绝对值的最小的一个消息。

使用msgget()函数创建打开队列；
int msgget(key_t key,int msgflg)
key为键值，可设置成常数IPC_PRIVATE，或由ftok获取；key_t ftok(char *pathname,char proj)

使用msgrcv()函数从队列中读数据；
int msgsnd(int msqid,struct msgbuf *msgp,size_t msgz,int msgflg)
sqid为消息队列ID，由内核反馈；
msgp：指向消息缓冲区的指针，此位置用来暂时存储发送和接收的消息，是一个用户可定义的通用结构；

使用msgsnd()函数写数据到队列中；
使用msgctl()函数控制消息队列；
int main()  
{  
    int running = 1;  
    int msgid = -1;  
    struct msg_st data;  
    long int msgtype = 0; //注意1  
  
    //建立消息队列  
    msgid = msgget((key_t)1234, 0666 | IPC_CREAT);  
    if(msgid == -1)  
    {  
        fprintf(stderr, "msgget failed with error: %d\n", errno);  
        exit(EXIT_FAILURE);  
    }  
    //从队列中获取消息，直到遇到end消息为止  
    while(running)  
    {  
        if(msgrcv(msgid, (void*)&data, BUFSIZ, msgtype, 0) == -1)  
        {  
            fprintf(stderr, "msgrcv failed with errno: %d\n", errno);  
            exit(EXIT_FAILURE);  
        }  
        printf("You wrote: %s\n",data.text);  
        //遇到end结束  
        if(strncmp(data.text, "end", 3) == 0)  
            running = 0;  
    }  
    //删除消息队列  
    if(msgctl(msgid, IPC_RMID, 0) == -1)  
    {  
        fprintf(stderr, "msgctl(IPC_RMID) failed\n");  
        exit(EXIT_FAILURE);  
    }  
    exit(EXIT_SUCCESS);  
}  
==============================================================================
    msgid = msgget((key_t)1234, 0666 | IPC_CREAT);  
    if(msgid == -1)  
    {  
        fprintf(stderr, "msgget failed with error: %d\n", errno);  
        exit(EXIT_FAILURE);  
    }  
  
    //向消息队列中写消息，直到写入end  
    while(running)  
    {  
        //输入数据  
        printf("Enter some text: ");  
        fgets(buffer, BUFSIZ, stdin);  
        data.msg_type = 1;    //注意2  
        strcpy(data.text, buffer);  
        //向队列发送数据  
        if(msgsnd(msgid, (void*)&data, MAX_TEXT, 0) == -1)  
        {  
            fprintf(stderr, "msgsnd failed\n");  
            exit(EXIT_FAILURE);  
        }  
        //输入end结束输入  
        if(strncmp(buffer, "end", 3) == 0)  
            running = 0;  
        sleep(1);  
    }  
    exit(EXIT_SUCCESS);  
如果把注意1，即msgreceive.c文件main函数中的语句由long int msgtype = 0;改变为long int msgtype = 2;会发生什么情况，msgreceive将不能接收到程序msgsend发送的信息。因为在调用msgrcv函数时，如果msgtype（第四个参数）大于零，则将只获取具有相同消息类型的第一个消息，修改后获取的消息类型为2，而msgsend发送的消息类型为1，所以不能被msgreceive程序接收。

==============================================================================

4.共享内存（shared memory）：
可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。
总之，当一个程序想和另外一个程序通信的时候，那内存将会为这两个程序生成一块公共的内存区域。
这块被两个进程分享的内存区域叫做共享内存。
由于全部进程共享同一块内存，共享内存在各种进程间通信方式中具有最高的效率。

共享内存段紧靠在栈之下，最大限制为32M

共享内存的实现分为两个步骤:
创建共享内存，使用shmget函数。
映射共享内存。将这段创建的共享内存映射到详细的进程空间去，使用shmat函数。
key_t ftok(char *pathname,char proj);
共享内存映射
void *shmat(int shm_id, const void *shm_addr, int shmflg);
共享内存控制
int shmctl(int shm_id, int cmd, struct shmid_ds *buf);
共享内存分离 
int shmdt(const void *shm_addr);
创建共享内存 
int shmget(key_t key, size_t size, int shmflg);

（1）进程通过调用shmget（Shared Memory GET，获取共享内存）来分配一个共享内存块。
（2）要让一个进程获取对一块共享内存的访问，这个进程必须先调用 shmat（SHared Memory Attach，绑定到共享内存）。将 shmget 返回的共享内存标识符 SHMID 传递给这个函数作为第一个参数。该函数的第二个参数是一个指针，指向您希望用于映射该共享内存块的进程内存地址；如果您指定NULL则Linux会自动选择一个合适的地址用于映射。
（3）调用 shmctl（"Shared Memory Control"，控制共享内存）函数会返回一个共享内存块的相关信息。要删除一个共享内存块，则应将 IPC_RMID 作为第二个参数，而将 NULL 作为第三个参数。当最后一个绑定该共享内存块的进程与其脱离时，该共享内存块将被删除。

==============================================================================

5.信号量（semaphore）：
主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段。
P操作原语：
sem 减1
若sem 大于等于0，线程继续执行.
若sem < 0 ，线程进入阻塞队列.

V 操作原语：
sem加1
若sem 大于 0, 线程继续执行
若sem 小于等于0,唤醒阻塞队例的线程

信号量是一个特殊的变量，程序对其访问都是原子操作，且只允许对它进行等待（即P(信号变量))和发送（即V(信号变量))信息操作。最简单的信号量是只能取0和1的变量，这也是信号量最常见的一种形式，叫做二进制信号量。而可以取多个正整数的信号量被称为通用信号量。

信号量是一种特殊的变量，访问具有原子性。
只允许对它进行两个操作：
1)等待信号量
当信号量值为0时，程序等待；当信号量值大于0时，信号量减1，程序继续运行。
2)发送信号量
将信号量值加1。
我们使用信号量，来解决进程或线程间共享资源引发的同步问题。

int semget(key_t key,int num_sems,int sem_flags);
key:信号量键值，可以理解为信号量的唯一性标记。
num_sems:信号量的数目，一般为1
sem_flags:有两个值，IPC_CREATE和IPC_EXCL，
IPC_CREATE表示若信号量已存在，返回该信号量标识符。
IPC_EXCL表示若信号量已存在，返回错误。
返回值：相应的信号量标识符，失败返回-1

int semop(int sem_id,struct sembuf *sem_opa,size_t num_sem_ops);
sem_id:信号量标识符
sem_opa:结构如下
struct sembuf{  
    short sem_num;//除非使用一组信号量，否则它为0  
    short sem_op;//信号量在一次操作中需要改变的数据，通常是两个数，一个是-1，即P（等待）操作，  
                    //一个是+1，即V（发送信号）操作。  
    short sem_flg;//通常为SEM_UNDO,使操作系统跟踪信号，  
                    //并在进程没有释放该信号量而终止时，操作系统释放信号量  
}; 

int semctl(int sem_id,int sem_num,int command,[union semun sem_union]);
command:有两个值SETVAL,IPC_RMID，分别表示初始化和删除信号量。
sem_union:可选参数，结构如下：
union semun{  
    int val; 
    struct semid_ds *buf;  
    unsigned short *arry;  
}; 
一般用到的是val,表示要传给信号量的初始值。
==============================================================================

6.套接字（socket）；
这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。

==============================================================================

管道与文件描述符,文件指针的关系? 
答: 其实管道的使用方法与文件类似,都能使用read,write,open等普通IO函数. 管道描述符类似于文件描述符. 事实上, 管道使用的描述符, 文件指针和文件描述符最终都会转化成系统中SOCKET描述符. 都受到系统内核中SOCKET描述符的限制. 本质上LINUX内核源码中管道是通过空文件来实现.

管道的使用方法? 
答: 主要有下面几种方法: 1)pipe, 创建一个管道,返回2个管道描述符.通常用于父子进程之间通讯. 2)popen, pclose: 这种方式只返回一个管道描述符,常用于通信另一方是stdin or stdout; 3)mkpipe: 命名管道, 在许多进程之间进行交互.

管道与系统IPC之间的优劣比较? 
答: 
管道: 优点是所有的UNIX实现都支持, 并且在最后一个访问管道的进程终止后,管道就被完全删除;缺陷是管道只允许单向传输或者用于父子进程之间.
系统IPC: 优点是功能强大,能在毫不相关进程之间进行通讯; 缺陷是关键字KEY_T使用了内核标识,占用了内核资源,而且只能被显式删除,而且不能使用SOCKET的一些机制,例如select,epoll等.

==============================================================================

Write函数

      Ssize_t write(int fd,const void*buf,size_t nbytes);

      Write函数将buf中的nbytes字节内容写入到文件描述符中，成功返回写的字节数，失败返回-1.并设置errno变量。在网络程序中，当我们向套接字文件描述舒服写数据时有两种可能：

      1、write的返回值大于0，表示写了部分数据或者是全部的数据，这样用一个while循环不断的写入数据，但是循环过程中的buf参数和nbytes参数是我们自己来更新的，也就是说，网络编程中写函数是不负责将全部数据写完之后再返回的，说不定中途就返回了！

      2、返回值小于0，此时出错了，需要根据错误类型进行相应的处理。

      如果错误是EINTR表示在写的时候出现了中断错误，如果是EPIPE表示网络连接出现了问题。

Read函数

      Ssize_t read(int fd,void*buf,size_t nbyte)

      Read函数是负责从fd中读取内容，当读取成功时，read返回实际读取到的字节数，如果返回值是0，表示已经读取到文件的结束了，小于0表示是读取错误。

      如果错误是EINTR表示在写的时候出现了中断错误，如果是EPIPE表示网络连接出现了问题。

      虽然写了100个字节，但并不能保证read一次即读100个字节，写的时候也并非写100就成功了，write和read实际成功读写的字节数由返回值确定。

==============================================================================

临界资源
  临界资源是一次仅允许一个进程使用的共享资源。各进程采取互斥的方式，实现共享的资源称作临界资源。属于临界资源的硬件有，打印机，磁带机等；软件有消息队列，变量，数组，缓冲区等。诸进程间采取互斥方式，实现对这种资源的共享。

临界区：
  每个进程中访问临界资源的那段代码称为临界区（criticalsection），每次只允许一个进程进入临界区，进入后，不允许其他进程进入。不论是硬件临界资源还是软件临界资源，多个进程必须互斥的对它进行访问。多个进程涉及到同一个临界资源的的临界区称为相关临界区。使用临界区时，一般不允许其运行时间过长，只要运行在临界区的线程还没有离开，其他所有进入此临界区的线程都会被挂起而进入等待状态，并在一定程度上影响程序的运行性能。

==============================================================================

多线程如何同步：

临界区、互斥区、事件、信号量四种方式

==============================================================================

临界区（Critical Section）、互斥量（Mutex）、信号量（Semaphore）、事件（Event）的区别
1）、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。

2）、互斥量：采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享，还能实现不同应用程序的公共资源安全共享 .互斥量比临界区复杂。因为使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。

3）、信号量：它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目 .信号量对象对线程的同步方式与前面几种方法不同，信号允许多个线程同时使用共享资源，这与操作系统中的PV操作相同。它指出了同时访问共享资源的线程最大数目。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。

PV操作及信号量的概念都是由荷兰科学家E.W.Dijkstra提出的。信号量S是一个整数，S大于等于零时代表可供并发进程使用的资源实体数，但S小于零时则表示正在等待使用共享资源的进程数。
　　 P操作申请资源：
　　（1）S减1；
　　（2）若S减1后仍大于等于零，则进程继续执行；
　　（3）若S减1后小于零，则该进程被阻塞后进入与该信号相对应的队列中，然后转入进程调度。
　　
　　V操作 释放资源：
　　（1）S加1；
　　（2）若相加结果大于零，则进程继续执行；
　　（3）若相加结果小于等于零，则从该信号的等待队列中唤醒一个等待进程，然后再返回原进程继续执行或转入进程调度。
4）、事 件： 通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作 .

总结：
　　1） 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说它可以跨越进程使用。所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。
　　2） 互斥量（Mutex），信号灯（Semaphore），事件（Event）都可以被跨越进程使用来进行同步数据操作，而其他的对象与数据同步操作无关，但对于进程和线程来讲，如果进程和线程在运行状态则为无信号状态，在退出后为有信号状态。所以可以使用WaitForSingleObject来等待进程和线程退出。
　　3） 通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号灯对象可以说是一种资源计数器。

==============================================================================

信号量和互斥体之间的区别

概念上的区别：

信号量：是进程间（线程间）同步用的，一个进程（线程）完成了某一个动作就通过信号量告诉别的进程（线程），别的进程（线程）再进行某些动作。有二值和多值信号量之分。

互斥锁：是线程间互斥用的，一个线程占用了某一个共享资源，那么别的线程就无法访问，直到这个线程离开，其他的线程才开始可以使用这个共享资源。可以把互斥锁看成二值信号量。

上锁时：

信号量: 只要信号量的value大于0，其他线程就可以sem_wait成功，成功后信号量的value减一。若value值不大于0，则sem_wait阻塞，直到sem_post释放后value值加一。一句话，信号量的value>=0。

互斥锁: 只要被锁住，其他任何线程都不可以访问被保护的资源。如果没有锁，获得资源成功，否则进行阻塞等待资源可用。一句话，线程互斥锁的vlaue可以为负数。

使用场所： 
信号量主要适用于进程间通信，当然，也可用于线程间通信。而互斥锁只能用于线程间通信。

==============================================================================

信号与信号量的区别：
1.信号：（signal）是一种处理异步事件的方式。信号时比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程外，还可以发送信号给进程本身。linux除了支持unix早期的信号语义函数，还支持语义符合posix.1标准的信号函数sigaction。
2.信号量：（Semaphore）进程间通信处理同步互斥的机制。是在多线程环境下使用的一种设施, 它负责协调各个线程, 以保证它们能够正确、合理的使用公共资源。

==============================================================================

信号量/互斥体和自旋锁的区别

信号量/互斥体允许进程睡眠属于睡眠锁，自旋锁则不允许调用者睡眠，而是让其循环等待，所以有以下区别应用 
1）、信号量和读写信号量适合于保持时间较长的情况，它们会导致调用者睡眠，因而自旋锁适合于保持时间非常短的情况 
2）、自旋锁可以用于中断，不能用于进程上下文(会引起死锁)。而信号量不允许使用在中断中，而可以用于进程上下文 
3）、自旋锁保持期间是抢占失效的，自旋锁被持有时，内核不能被抢占，而信号量和读写信号量保持期间是可以被抢占的

另外需要注意的是 
1）、信号量锁保护的临界区可包含可能引起阻塞的代码，而自旋锁则绝对要避免用来保护包含这样代码的临界区，因为阻塞意味着要进行进程的切换，如果进程被切换出去后，另一进程企图获取本自旋锁，死锁就会发生。 
2）、在你占用信号量的同时不能占用自旋锁，因为在你等待信号量时可能会睡眠，而在持有自旋锁时是不允许睡眠的。

==============================================================================

进程和线程的区别：

答：线程是指进程内的一个执行单元,也是进程内的可调度实体。与进程的区别:

(1)调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位。

(2)并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行。

(3)拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源.

(4)系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。

进程间 堆栈独立
线程间 共享堆，栈独立
一个线程挂掉，则进程就会挂掉
所以说多进程比多线程更健壮

==============================================================================

epoll与select的区别：

问题的引出，当需要读两个以上的I/O的时候，如果使用阻塞式的I/O，那么可能长时间的阻塞在一个描述符上面，另外的描述符虽然有数据但是不能读出来，这样实时性不能满足要求，大概的解决方案有以下几种：

1.使用多进程或者多线程，但是这种方法会造成程序的复杂，而且对与进程与线程的创建维护也需要很多的开销。（Apache服务器是用的子进程的方式，优点可以隔离用户）

2.用一个进程，但是使用非阻塞的I/O读取数据，当一个I/O不可读的时候立刻返回，检查下一个是否可读，这种形式的循环为轮询（polling），这种方法比较浪费CPU时间，因为大多数时间是不可读，但是仍花费时间不断反复执行read系统调用。

3.异步I/O（asynchronous I/O），当一个描述符准备好的时候用一个信号告诉进程，但是由于信号个数有限，多个描述符时不适用。

4.一种较好的方式为I/O多路转接（I/O multiplexing）（貌似也翻译多路复用），先构造一张有关描述符的列表（epoll中为队列），然后调用一个函数，直到这些描述符中的一个准备好时才返回，返回时告诉进程哪些I/O就绪。select和epoll这两个机制都是多路I/O机制的解决方案，select为POSIX标准中的，而epoll为Linux所特有的。

区别（epoll相对select优点）主要有三：

1.select的句柄数目受限，在linux/posix_types.h头文件有这样的声明：#define __FD_SETSIZE    1024  表示select最多同时监听1024个fd。而epoll没有，它的限制是最大的打开文件句柄数目。

2.epoll的最大好处是不会随着FD的数目增长而降低效率，在selec中采用轮询处理，其中的数据结构类似一个数组的数据结构，而epoll是维护一个队列，直接看队列是不是空就可以了。epoll只会对"活跃"的socket进行操作---这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有"活跃"的socket才会主动的去调用 callback函数（把这个句柄加入队列），其他idle状态句柄则不会，在这点上，epoll实现了一个"伪"AIO。但是如果绝大部分的I/O都是“活跃的”，每个I/O端口使用率很高的话，epoll效率不一定比select高（可能是要维护队列复杂）。

3.使用mmap加速内核与用户空间的消息传递。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的。

==============================================================================
epoll中et和lt的区别与实现原理：

epoll有2种工作方式:LT和ET。
LT(level triggered 水平触发)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件
描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你 的，所以，这种模式编程出错
误可能性要小一点。传统的select/poll都是这种模型的代表．

ET (edge-triggered 边缘触发)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核
通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述 符发送更多的就绪通知，直到你做了某些操作
导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致 了一个
EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only 
once),不过在TCP协议中，ET模式的加速效用仍需要更多的benchmark确认。
epoll只有epoll_create,epoll_ctl,epoll_wait 3个系统调用。

==============================================================================
linux下的锁
https://www.cnblogs.com/tgycoder/p/5442040.html

==============================================================================
send函数缓存问题
send()函数默认情况下会使用Nagle算法。Nagle算法通过将未确认的数据存入缓冲区直到积攒到一定数量一起发送的方法。来降低主机发送零碎小数据包的数目。所以假设send()函数发送数据过快的话，该算法会将一些数据打包后统一发出去。假设不了接这样的情况，接收端採会遇到看似非常奇怪的问题，比方成功recv()的次数与成功send()的次数不相等。在这中情况下，接收端能够通过recv()的返回值是否为0来推断发送端是否发送完成。

==============================================================================
Nagle算法：
是为了减少广域网的小分组数目，从而减小网络拥塞的出现；
该算法要求一个tcp连接上最多只能有一个未被确认的未完成的小分组，在该分组ack到达之前不能发送其他的小分组，tcp需要收集这些少量的分组，并在ack到来时以一个分组的方式发送出去；其中小分组的定义是小于MSS的任何分组；
该算法的优越之处在于它是自适应的，确认到达的越快，数据也就发哦送的越快；而在希望减少微小分组数目的低速广域网上，则会发送更少的分组；

设计规则如下：

　　（1）如果包长度达到最大报文长度（MSS，Maximum Segment Size），则允许发送；

　　（2）如果该包含有FIN，则允许发送；

　　（3）设置了TCP_NODELAY选项，则允许发送；

　　（4）未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送；

　　（5）上述条件都未满足，但发生了超时（一般为200ms），则立即发送。


关闭Nagle：
setsockopt(fd,IPPROTO_TCP,TCP_NODELAY,(char*)&flag,sizeof(flag));

==============================================================================
延迟ACK：
如果tcp对每个数据包都发送一个ack确认，那么只是一个单独的数据包为了发送一个ack代价比较高，所以tcp会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ack，如果在延迟ack定时器触发时候，发现ack尚未发送，则立即单独发送；
延迟ACK好处：
(1) 避免糊涂窗口综合症；
(2) 发送数据的时候将ack捎带发送，不必单独发送ack；
(3) 如果延迟时间内有多个数据段到达，那么允许协议栈发送一个ack确认多个报文段；

==============================================================================
当Nagle遇上延迟ACK：
试想如下典型操作，写-写-读，即通过多个写小片数据向对端发送单个逻辑的操作，两次写数据长度小于MSS，当第一次写数据到达对端后，对端延迟ack，不发送ack，而本端因为要发送的数据长度小于MSS，所以nagle算法起作用，数据并不会立即发送，而是等待对端发送的第一次数据确认ack；这样的情况下，需要等待对端超时发送ack，然后本段才能发送第二次写的数据，从而造成延迟；

由于有Nagle算法，如果发送端启用了Nagle算法，接收端启用了TCP Delayed Acknowledge。当发送端发起两次写一次读的时候，第一次写，由于TCP没有等待ACK，直接发出去了，而第二次写的时候，第一次写的ACK还没有接收到，从而等待；而接收端有Delayed Acknowledge机制，会等待40ms以提供合并多个ACK的机会。Nagle算法的使用在一些实时性要求比较高的场合，会引起一些问题。比如项目中设计的UI鼠标远程控制远端的机器时，发现远端的鼠标操作很卡顿，这是因为鼠标消息的发送端由于Nagle算法的默认开启，是有延迟的，

==============================================================================
如下场景考虑关闭Nagle算法：
(1) 对端不向本端发送数据，并且对延时比较敏感的操作；这种操作没法捎带ack；
(2) 如上写-写-读操作；对于此种情况，优先使用其他方式，而不是关闭Nagle算法：
--使用writev，而不是两次调用write，单个writev调用会使tcp输出一次而不是两次，只产生一个tcp分节，这是首选方法；
--把两次写操作的数据复制到单个缓冲区，然后对缓冲区调用一次write；
--关闭Nagle算法，调用write两次；有损于网络，通常不考虑；
setsockopt(fd,IPPROTO_TCP,TCP_NODELAY,(char*)&flag,sizeof(flag));

==============================================================================
库函数是语言本身的一部分，而系统函数是内核提供给应用程序的接口，属于系统的一部分。
函数库调用是语言或应用程序的一部分，而系统调用是操作系统的一部分。
用户应用程序访问并使用内核所提供的各种服务的途径即是系统调用。在内核和用户应用程序相交界的地方，内核提供了一组系统调用接口，通过这组接口，应用程序可以访问系统硬件和各种操作系统资源。 
1.系统调用是为了方便应用使用操作系统的接口，而库函数是为了方便人们编写应用程序而引出的，比如你自己编写一个函数其实也可以说就是一个库函数。
2.系统调用可以理解为内核提供给我们在用户态用的接口函数，可以认为是某种内核的库函数。
3.read就是系统调用,而fread就是C标准库函数.

==============================================================================

1.进程上下文：
（1）进程上文：其是指进程由用户态切换到内核态是需要保存用户态时cpu寄存器中的值，进程状态以及堆栈上的内容，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。
（2）进程下文：其是指切换到内核态后执行的程序，即进程运行在内核空间的部分。

2.中断上下文：
（1）中断上文：硬件通过中断触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。中断上文可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境（主要是当前被中断的进程环境。
（2）中断下文：执行在内核空间的中断服务程序。

==============================================================================

内核运行在最高级别（内核态），这个级别几乎可以使用处理器的所有资源，而应用程序运行在较低级别（用户态），在这个级别的用户不能对硬件进行直接访问以及对内存的非授权访问。内核态和用户态有自己的内存映射，即自己的地址空间。

当工作在用户态的进程想访问某些内核才能访问的资源时，必须通过系统调用或者中断切换到内核态，由内核代替其执行。进程上下文和中断上下文就是完成这两种状态切换所进行的操作总称。我将其理解为保存用户空间状态是上文，切换后在内核态执行的程序是下文。

==============================================================================

1.进程上下文主要是异常处理程序和内核线程。内核之所以进入进程上下文是因为进程自身的一些工作需要在内核中做。例如，系统调用是为当前进程服务的，异常通常是处理进程导致的错误状态等。

2.中断上下文是由于硬件发生中断时会触发中断信号请求，请求系统处理中断，执行中断服务子程序。

==============================================================================
进程切换分两步
1.切换页目录以使用新的地址空间。
2.切换内核栈和硬件上下文。

对于linux来说，线程和进程的最大区别就在于地址空间。
对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。所以明显是进程切换代价大

线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor’s Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题

==============================================================================

针对多线程程序来说，为了防止每个线程占用过多内存， 它们会被规定一个最大栈空间，
如果用户程序没有显式指定大小的话， 系统就会分配一个缺省值，这个值在不同的平台可能会
不一样，比如x86系统往往是10M, MIPS可能是8M, ARM一般是4M或者2M, 可以用ulimit命令查到。
但有一点需要注意，这个查到的栈空间是子线程的，主线程往往会比这个值大很多,
所以栈溢出一般都发生在子线程中。
由于有了栈溢出的风险， 所以大空间的局部变量，alloca的参数过大都是要避免的，
如果非得要用大内存，就请考虑堆空间吧！

==============================================================================
Linux下，线程和进程区别不大，都有task_struct进程描述符。多线程进程可以看作是几个共享地址空间的进程的集合。但多线程一定是由一个主线程开始，这个主线程启动其他线程。主线程的线程栈在内核空间位置附近，大小为8MB，其他线程的线程栈是主线程在调用pthread_create创建线程时，由mmap分配的，所以这些线程栈在mmap的区域内，跟共享库入口同属一个区域，phtread_t tid中存储的就是线程结构体在mmap区域中的入口。普通线程栈的默认大小也是8MB，但是因为是动态分配的，所以可以在线程属性设置函数中调整线程栈的大小（主线程也可以修改栈大小）。线程中声明的局部变量在线程的数据结构体中，当然在mmap分配的区域中。可以比较这些变量的地址和tid中存储的值。

==============================================================================

创建一个线程默认的状态是joinable, 如果一个线程结束运行但没有被join,则它的状态类似于进程中的Zombie Process,即还有一部分资源没有被回收（退出状态码），所以创建线程者应该调用pthread_join来等待线程运行结束，并可得到线程的退出代码，回收其资源（类似于wait,waitpid)
但是调用pthread_join(pthread_id)后，如果该线程没有运行结束，调用者会被阻塞，在有些情况下我们并不希望如此，比如在Web服务器中当主线程为每个新来的链接创建一个子线程进行处理的时候，主线程并不希望因为调用pthread_join而阻塞（因为还要继续处理之后到来的链接），这时可以在子线程中加入代码
pthread_detach(pthread_self()) 
或者父线程调用 
pthread_detach(thread_id)（非阻塞，可立即返回） 
这将该子线程的状态设置为detached,则该线程运行结束后会自动释放所有资源。

==============================================================================
Linux上进程有5种状态: 
1. 运行(正在运行或在运行队列中等待) 
2. 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 
3. 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 
4. 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 
5. 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行)

Linux进程状态：R (TASK_RUNNING)，可执行状态。
只有在该状态的进程才可能在CPU上运行。而同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。
很多操作系统教科书将正在CPU上执行的进程定义为RUNNING状态、而将可执行但是尚未被调度执行的进程定义为READY状态，这两种状态在linux下统一为 TASK_RUNNING状态。

Linux进程状态：S (TASK_INTERRUPTIBLE)，可中断的睡眠状态。
处于这个状态的进程因为等待某某事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。
通过ps命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态（除非机器的负载很高）。毕竟CPU就这么一两个，进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU又怎么响应得过来。

Linux进程状态：D (TASK_UNINTERRUPTIBLE)，不可中断的睡眠状态。
与TASK_INTERRUPTIBLE状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号。
绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。否则你将惊奇的发现，kill -9竟然杀不死一个正在睡眠的进程了！于是我们也很好理解，为什么ps命令看到的进程几乎不会出现TASK_UNINTERRUPTIBLE状态，而总是TASK_INTERRUPTIBLE状态。
而TASK_UNINTERRUPTIBLE状态存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。（参见《linux内核异步中断浅析》）
在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到。
linux系统中也存在容易捕捉的TASK_UNINTERRUPTIBLE状态。执行vfork系统调用后，父进程将进入TASK_UNINTERRUPTIBLE状态，直到子进程调用exit或exec（参见《神奇的vfork》）。
通过下面的代码就能得到处于TASK_UNINTERRUPTIBLE状态的进程：
#include   void main() {  if (!vfork()) sleep(100);  }
然后我们可以试验一下TASK_UNINTERRUPTIBLE状态的威力。不管kill还是kill -9，这个TASK_UNINTERRUPTIBLE状态的父进程依然屹立不倒。

Linux进程状态：T (TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态。
向进程发送一个SIGSTOP信号，它就会因响应该信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。（SIGSTOP与SIGKILL信号一样，是非常强制的。不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数。）
向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。
当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。
对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。
而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。

Linux进程状态：Z (TASK_DEAD - EXIT_ZOMBIE)，退出状态，进程成为僵尸进程。
进程在退出的过程中，处于TASK_DEAD状态。
在这个退出过程中，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外。于是进程就只剩下task_struct这么个空壳，故称为僵尸。
之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在shell中，$?变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。
当然，内核也可以将这些信息保存在别的地方，而将task_struct结构释放掉，以节省一些空间。但是使用task_struct结构更为方便，因为在内核中已经建立了从pid到task_struct查找关系，还有进程间的父子关系。释放掉task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。
父进程可以通过wait系列的系统调用（如wait4、waitid）来等待某个或某些子进程的退出，并获取它的退出信息。然后wait系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉。
子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来“收尸”。这个信号默认是SIGCHLD，但是在通过clone系统调用创建子进程时，可以设置这个信号。
通过下面的代码能够制造一个EXIT_ZOMBIE状态的进程：
#include   void main() {  if (fork())  while(1) sleep(100); }
只要父进程不退出，这个僵尸状态的子进程就一直存在。那么如果父进程退出了呢，谁又来给子进程“收尸”？
当进程退出的时候，会将它的所有子进程都托管给别的进程（使之成为别的进程的子进程）。托管给谁呢？可能是退出进程所在进程组的下一个进程（如果存在的话），或者是1号进程。所以每个进程、每时每刻都有父进程存在。除非它是1号进程。
1号进程，pid为1的进程，又称init进程。
linux系统启动后，第一个被创建的用户态进程就是init进程。它有两项使命：
1、执行系统初始化脚本，创建一系列的进程（它们都是init进程的子孙）；
2、在一个死循环中等待其子进程的退出事件，并调用waitid系统调用来完成“收尸”工作；
init进程不会被暂停、也不会被杀死（这是由内核来保证的）。它在等待子进程退出的过程中处于TASK_INTERRUPTIBLE状态，“收尸”过程中则处于TASK_RUNNING状态。

Linux进程状态：X (TASK_DEAD - EXIT_DEAD)，退出状态，进程即将被销毁。
而进程在退出过程中也可能不会保留它的task_struct。比如这个进程是多线程程序中被detach过的进程（进程？线程？参见《linux线程浅析》）。或者父进程通过设置SIGCHLD信号的handler为SIG_IGN，显式的忽略了SIGCHLD信号。（这是posix的规定，尽管子进程的退出信号可以被设置为SIGCHLD以外的其他信号。）
此时，进程将被置于EXIT_DEAD退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以EXIT_DEAD状态是非常短暂的，几乎不可能通过ps命令捕捉到。

==============================================================================

在linux中多进程的并发执行时，处理不当可能会出现 孤儿进程和僵尸进程；它们出现的情况如下：
1.孤儿进程出现在: 父进程先于子进程结束时。（当用ps -a 时，可以看到父进程已不在了，而子进程依旧在的情形）
2.僵尸进程出现在：子进程先于父进程结束，而父进程未用 wait（）或者waitpid(),来监听子进程的状态，使子进程的资源迟迟不能释放的情形；

如果父进程先退出,子进程还没退出那么子进程将被托孤给init进程,这时子进程的父进程就是init进程(1号进程)。

在Linux进程的状态中，僵尸进程是非常特殊的一种，它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出状态等信息供其他进程收集，除此之外，僵尸进程不再占有任何内存空间。它需要它的父进程来为它收尸，如果他的父进程没安装SIGCHLD信号处理函数调用wait或waitpid()等待子进程结束，又没有显式忽略该信号，那么它就一直保持僵尸状态，如果这时父进程结束了，那么init进程自动会接手这个子进程，为它收尸，它还是能被清除的。但是如果如果父进程是一个循环，不会结束，那么子进程就会一直保持僵尸状态，这就是为什么系统中有时会有很多的僵尸进程。

守护进程就是在后台运行,不与任何终端关联的进程,通常情况下守护进程在系统启动时就在运行,它们以root用户或者其他特殊用户(apache和postfix)运行,并能处理一些系统级的任务.习惯上守护进程的名字通常以d结尾(sshd),但这些不是必须的.
下面介绍一下创建守护进程的步骤
调用fork(),创建新进程,它会是将来的守护进程.
在父进程中调用exit,保证子进程不是进程组长
调用setsid()创建新的会话区
将当前目录改成跟目录(如果把当前目录作为守护进程的目录,当前目录不能被卸载他作为守护进程的工作目录)
将标准输入,标注输出,标准错误重定向到/dev/null

==============================================================================
子进程死后，会发送SIGCHLD信号给父进程，父进程收到此信号后，执行waitpid()函数为子进程收尸。就是基于这样的原理：就算父进程没有调用wait，内核也会向它发送SIGCHLD消息，而此时，尽管对它的默认处理是忽略，如果想响应这个消息，可以设置一个处理函数。

处理SIGCHLD信号并不是必须的。
但对于某些进程，特别是服务器进程往往在请求到来时生成子进程处理请求。
如果父进程不等待子进程结束，子进程将成为僵尸进程（zombie）从而占用系统资源。
如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。
在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。
signal(SIGCHLD,SIG_IGN);
这样，内核在子进程结束时不会产生僵尸进程。这一点与BSD4不同，BSD4下必须显式等待子进程结束才能释放僵尸进程
或者
用两次fork()，而且使紧跟的子进程直接退出，使得孙子进程成为孤儿进程，从而init进程将负责清除这个孤儿进程。

==============================================================================

多线程的那点儿事（之读写锁）
在编写多线程的时候，有一种情况是十分常见的。那就是，有些公共数据修改的机会比较少。相比较改写，它们读的机会反而高的多。通常而言，在读的过程中，往往伴随着查找的操作，中间耗时很长。给这种代码段加锁，会极大地降低我们程序的效率。那么有没有一种方法，可以专门处理这种多读少写的情况呢？有，那就是读写锁。
文章总结：
    （1）读写锁的优势只有在多读少写、代码段运行时间长这两个条件下才会效率达到最大化；
    （2）任何公共数据的修改都必须在锁里面完成；
    （3）读写锁有自己的应用场所，选择合适的应用环境十分重要；
    （4）编写读写锁很容易出错，朋友们应该多加练习；
    （5）读锁和写锁一定要分开使用，否则达不到效果。

读写锁应用的场合
　　我们有时会遇到对同一个内存区域如数组或者链表进行多线程读写的情况,一般来说有以下几种处理方式: 1.不加任何限制,多见于读取写入都很快的情况,但有时也会出现问题. 2.对读写函数都加以同步互斥,这下问题是没了,但效率也下去了,比如说两个读取线程不是非要排队进入不可. 3.使用读写锁,安全和效率都得到了解决,特别合适读线程多于写线程的情况.也就是下面将要展现的模式.

读写锁的意图
　　读写锁的本意是分别对读写状态进行互斥区分,有互斥时才加锁,否则放行.互斥的情况有: 1.读写互斥. 2.写写互斥. 不互斥的情况是:读读,这种情况不该加以限制. 程序就是要让锁对象知道当前读写状态,再根据情况对读写的线程进行锁定和解锁。

当有一个读线程在操作时，其它的写线程无法进行操作，读线程可以正常操作，互不干扰。
当有一个写线程在操作时，其它的读线程无法进行操作

小结
当多个线程试图对同一内容进行读写操作时适合使用读写锁。
请理解并记住ReadWriteLock类读写锁的写法.
读写锁相对于线程互斥的优势在于高效，它不会对两个读线程进行盲目的互斥处理，当读线程数量多于写线程尤其如此，当全是写线程时两者等效。

读写锁实际是一种特殊的自旋锁，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。这种锁相对于自旋锁而言，能提高并发性，因为在多处理器系统中，它允许同时有多个读者来访问共享资源，最大可能的读者数为实际的逻辑CPU数。写者是排他性的，一个读写锁同时只能有一个写者或多个读者（与CPU数相关），但不能同时既有读者又有写者。
==============================================================================
互斥锁 mutex：
在访问共享资源之前对进行加锁操作，在访问完成之后进行解锁操作。 
加锁后，任何其他试图再次加锁的线程会被阻塞，直到当前进程解锁。 
如果解锁时有一个以上的线程阻塞，那么所有该锁上的线程都被编程就绪状态， 
第一个变为就绪状态的线程又执行加锁操作，那么其他的线程又会进入等待。 
在这种方式下，只有一个线程能够访问被互斥锁保护的资源。

读写锁 rwlock（也叫作共享互斥锁：读模式共享，写模式互斥）：
读写锁有三种状态：读加锁状态、写加锁状态和不加锁状态 
一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。（这也是它能够实现高并发的一种手段） 
当读写锁在写加锁模式下，任何试图对这个锁进行加锁的线程都会被阻塞，直到写进程对其解锁。 
当读写锁在读加锁模式先，任何线程都可以对其进行读加锁操作，但是所有试图进行写加锁操作的线程都会被阻塞，直到所有的读线程都解锁。 
所以读写锁非常适合对数据结构读的次数远远大于写的情况。

如果严格按照上述读写锁的操作进行的话，那么当读者源源不断到来的时候，写者总是得不到读写锁，就会造成不公平的状态。 
一种避免这种不公平状态的方法是： 
当处于读模式的读写锁接收到一个试图对其进行写模式加锁操作时，便会阻塞后面对其进行读模式加锁操作的线程。 
这样等到已经加读模式的锁解锁后，写进程能够访问此锁保护的资源。

自旋锁spinlock：
自旋锁的使用模式和互斥锁很类似。 
只是在加锁后，有线程试图再次执行加锁操作的时候，该线程不会阻塞，而处于循环等待的忙等状态（CPU不能够做其他事情）。 
所以自旋锁适用的情况是：锁被持有的时间较短，而且进程并不希望在重新调度上花费太多的成本。

RCU锁（Read-Copy Update）：读-复制 更新
实际上是对读写锁的一种改进，同样是对读者线程和写者线程进行区别对待，只不过对待的方式是不同的。 
读写锁中只允许多个读者同时访问被保护的数据，但是在RCU中允许多个读者和多个写者同时访问被保护的资源。写者的同步开销则取决于使用的写者间同步机制，RCU并不对此进行支持。 
RCU中，读者不需要使用锁，要访问资源尽管访问就好了。 
RCU中，写者的同步开销比较大，要等到所有的读者都访问完成了才能够对被保护的资源进行更新。 
写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收器注册一个回调函数以便在适当的时机执行真正的修改操作。 
读者必须提供一个信号给写者以便写者能够确定数据可以被安全地释放或修改的时机。有一个专门的垃圾收集器来探测读者的信号，一旦所有的读者都已经发送信号告知它们都不在使用被RCU保护的数据结构，垃圾收集器就调用回调函数完成最后的数据释放或修改操作。 
写者要从链表中删除元素 B，它首先遍历该链表得到指向元素 B 的指针，然后修改元素 B 的前一个元素的 next 指针指向元素 B 的 next 指针指向的元素C，修改元素 B 的 next 指针指向的元素 C 的 prep 指针指向元素 B 的 prep指针指向的元素 A,在这期间可能有读者访问该链表，修改指针指向的操作是原子的，所以不需要同步，而元素 B 的指针并没有去修改，因为读者可能正在使用 B 元素来得到下一个或前一个元素。写者完成这些操作后注册一个回调函数以便在 grace period 之后删除元素 B，然后就认为已经完成删除操作。垃圾收集器在检测到所有的CPU不在引用该链表后，即所有的 CPU 已经经历了 quiescent state（上下文切换）,grace period（所有的CPU都经历了一次上下文切换） 已经过去后，就调用刚才写者注册的回调函数删除了元素 B。

适用于网络路由表的查询更新、设备状态表的维护、数据结构的延迟释放以及多径I/O设备的维护

==============================================================================

volatile的本意是“易变的” 因为访问寄存器要比访问内存单元快的多,所以编译器一般都会作减少存取内存的优化，但有可能会读脏数据。当要求使用volatile声明变量值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。精确地说就是，遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问；如果不使用valatile，则编译器将对所声明的语句进行优化。（简洁的说就是：volatile关键词影响编译器编译的结果，用volatile声明的变量表示该变量随时可能发生变化，与该变量有关的运算，不要进行编译优化，以免出错）

一个参数既可以是const还可以是volatile吗？
可以的，例如只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。
==============================================================================
线程安全性
如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。
或者说:一个类或者程序所提供的接口对于线程来说是原子操作或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题。
线程安全问题都是由全局变量及静态变量引起的。
若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。

==============================================================================
在/arch/x86/include/asm/page_64_types.h下有如下两行：

#define __START_KERNEL_map _AC(0xffffffff80000000, UL)
#define KERNEL_IMAGE_START _AC(0xffffffff80000000, UL)

这就是对空间大小的划分，在0xffffffff80000000之前的是给用户空间，在0xffffffff80000000之后的给内核空间，如果你现在手里有大约12G的内存想让内核态下可以使用大小10G的空间可以修改此值，将上面两句改为如下：

#define __START_KERNEL_map _AC(0xfffffffc00000000, UL)
#define KERNEL_IMAGE_START _AC(0xfffffffc00000000, UL)

然后，再将你的内核加载到连续的物理内存起始地址即可,这样内核就可以有16G寻址空间
物理地址分布情况可以查看e820的信息取得。

==============================================================================

死锁（Deadlock）的形成
打个比方，假设有P1和P2两个进程，都需要A和B两个资源，现在P1持有A等待B资源，而P2持有B等待A资源，两个都等待另一个资源而不肯释放资源，就这样无限等待中，这就形成死锁，这也是死锁的一种情况。给死锁下个定义，如果一组进程中每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的。

==============================================================================

==============================================================================
线程安全性
mutex
条件变量
死锁
race condition
false sharing
多线程debug调试
生产者消费者模型



