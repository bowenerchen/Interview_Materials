==============================================================================

同步和异步
同步就是烧开水，需要自己去轮询（每隔一段时间去看看水开了没），异步就是水开了，然后水壶会通知你水已经开了，你可以回来处理这些开水了。
同步和异步是相对于操作结果来说，会不会等待结果返回。
阻塞和非阻塞
阻塞就是说在煮水的过程中，你不可以去干其他的事情，非阻塞就是在同样的情况下，可以同时去干其他的事情。阻塞和非阻塞是相对于线程是否被阻塞。
其实，这两者存在本质的区别，它们的修饰对象是不同的。阻塞和非阻塞是指进程访问的数据如果尚未就绪，进程是否需要等待，简单说这相当于函数内部的实现区别，也就是未就绪时是直接返回还是等待就绪。
而同步和异步是指访问数据的机制,同步一般指主动请求并等待I/O操作完毕的方式,当数据就绪后在读写的时候必须阻塞,异步则指主动请求数据后便可以继续处理其它任务,随后等待I/O,操作完毕的通知,这可以使进程在数据读写时也不阻塞。

==============================================================================

同步和异步同步和异步是一种通信机制，涉及到调用方和被调用方，关注的是IO操作的执行过程及结果的返回方式，不同点在于双方在这两个方面的行为方式。
如果调用方需要保持等待直到IO操作完成进而通过返回获得结果，则是同步的；
如果调用方在IO操作的执行过程中不需要保持等待，而是在操作完成后被动的接受（通过消息或回调）被调用方推送的结果，则是异步的。

阻塞和非阻塞是一种调用机制，只涉及到调用方，关注的是IO操作的执行状态，不同点在于请求IO操作后，针对IO操作的状态，调用方的行为方式。
如果调用方等待IO操作完成后返回，则是阻塞的；
如果调用方不需要等待IO操作完成就立即返回，则是非阻塞的，非阻塞的情况下，常常需要多次调用去check，才能获得IO操作的结果。

==============================================================================

要说挂起、阻塞、睡眠难免让人想到进程生命周期中的阻塞态或者等待状态，而挂起和睡眠却没有出现在进程生命周期中，说明这三个其实在本质上区别并不那么大，但是既然称呼不同，应该就有不同的道理。

先说阻塞，既然它能出现在进程生命周期，必然是每个进程都会经历的一个阶段，众所周知，进程在运行过程中必然要获取资源，暂且不说CPU，进程运行肯定要和磁盘进行交互，继而发生IO操作，IO操作势必要引起等待，在资源未读取完成，进程必然要等待，那么在等待IO完成这个部分就是阻塞状态。所以从这里来看，阻塞是一种被动的方式，由于获取资源获取不到而引起的等待。

再说睡眠，睡眠就是一种主动的方式，其实个人认为睡眠和阻塞在一个层次上，为何这么说呢？当一个进程获取资源比如获取最普通的锁而失败后，可以有两种处理方式，1、自己睡眠，触发调度；2、忙等待，使用完自己的时间。所以从这里看，睡眠的确是一种主动的方式，且仅仅作为一种处理手段。当然睡眠不仅仅用于阻塞，更多的，我们可以在适当的时候设置让进程睡眠一定的时间，那么在这里，就可以发现，睡眠之前，我们已经预先规定了，你只能睡多长时间，这段时间过后，比必须返回来工作。

最后说挂起，挂起也是一种主动的行为，具体而言，挂起是系统层面对进程作出的合理操作。本来想说调度，但是进程调度作为专业术语指CPU资源的分配，那么这里就说操作。挂起的标志就是换出到外存，在外存的进程肯定是不能执行的，所以挂起的目的就很明显，在内存资源不足时，需要把一些进程换出到外存，给着急运行的进程腾地方。挂起倾向于换出阻塞态的进程，也可以是就绪态的进程。只是这个转换几乎不会采用，因为任意时刻，肯定可以找到在内存中的阻塞态进程，但也不能缺少这种直接把就绪转换到挂起的能力。

==============================================================================

网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。对于一次IO访问，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间，所以一般会经历两个阶段：
等待所有数据都准备好或者一直在等待数据，有数据的时候将数据拷贝到系统内核；
将内核缓存中数据拷贝到用户进程中；
对于socket流而言：
等待网络上的数据分组到达，然后被复制到内核的某个缓冲区；

把数据从内核缓冲区复制到应用进程缓冲区中；
https://www.cnblogs.com/George1994/p/6702084.html

==============================================================================

Linux的三个系统调用：open，socket，pipe 返回的都是描述符。
内核为每个进程维护了一个结构体struct task_struct，可称为进程表项、进程控制块（PCB: Process Control Block）或者进程描述符
其中struct files_struct *files;成员成为打开文件描述符表，其共用struct fdtable fdtab; 
说明普通的文件、套接字、管道等，都被抽象为文件，共同占用进程的打开文件描述符。

Linux这一套文件机制就相当于面向对象里面的多态，拿到一个文件描述符都可以进行read或者write。
但是具体的read和write却跟对应文件描述符的具体实现不同。比如socket的就是走网络，普通文件的就是走磁盘IO。


==============================================================================

进程间通信方式：
管道 信号 共享内存 socket 消息队列 信号量

==============================================================================

管道容量分为pipi capacity 和 pipe_buf .这两者的区别在于pipe_buf定义的是内核管道缓冲区的大小，这个值的大小是由内核设定的，这个值仅需一条命令就可以查到；而pipe capacity指的是管道的最大值，即容量，是内核内存中的一个缓冲区。

pipe_buf: 命令：ulimit -a |grep pipe

在终端输入该命令就会出现如下一表：

pipe size            (512 bytes, -p) 8

管道容量 sizeof(pipe_buf)= 512 bytes* 8 = 4kb
==============================================================================

ipcs
ipcs -q : 显示所有的消息队列

ipcs -qt : 显示消息队列的创建时间，发送和接收最后一条消息的时间

ipcs -qp: 显示往消息队列中放消息和从消息队列中取消息的进程ID

ipcs -q -i msgid: 显示该消息队列结构体中的消息信息：

ipcs -ql : 显示消息队列的限制信息：

取得ipc信息：
ipcs [-m|-q|-s]
-m 输出有关共享内存(shared memory)的信息
-q 输出有关信息队列(message queue)的信息
-s 输出有关“遮断器”(semaphore)的信息

删除ipc
ipcrm -m|-q|-s shm_id

==============================================================================

------管道

管道的优点是不需要加锁，缺点是默认缓冲区太小，只有4K，同时只适合父子进程间通信，而且一个管道只适合单向通信，如果要双向通信需要建立两个。而且不适合多个子进程，因为消息会乱，它的发送接收机制是用read/write这种适用流的，缺点是数据本身没有边界，需要应用程序自己解释，而一般消息大多是一个固定长的消息头，和一个变长的消息体，一个子进程从管道read到消息头后，消息体可能被别的子进程接收到

------消息队列

消息队列也不要加锁，默认缓冲区和单消息上限都要大一些，在我的suse10上是64K，它并不局限于父子进程间通信，只要一个相同的key，就可以让不同的进程定位到同一个消息队列上，它也可以用来给双向通信，不过稍微加个标识，可以通过消息中的type进行区分，比如一个任务分派进程，创建了若干个执行子进程，不管是父进程发送分派任务的消息，还是子进程发送任务执行的消息，都将type设置为目标进程的pid，因为msgrcv可以指定只接收消息类型为type的消息，这样就实现了子进程只接收自己的任务，父进程只接收任务结果

------共享内存

共享内存的几乎可以认为没有上限，它也是不局限与父子进程，采用跟消息队列类似的定位方式，因为内存是共享的，不存在任何单向的限制，最大的问题就是需要应用程序自己做互斥，有如下几种方案

1 只适用两个进程共享，在内存中放一个标志位，一定要声明为volatile，大家基于标志位来互斥，例如为0时第一个可以写，第二个就等待，为1时第一个等待，第二个可以写/读

2 也只适用两个进程，是用信号，大家等待不同的信号，第一个写完了发送信号2，等待信号1，第二个等待信号2，收到后读取/写入完，发送信号1，它不是用更多进程是因为虽然父进程可以向不同子进程分别发送信号，但是子进程收到信号会同时访问共享内存，产生不同子进程间的竞态条件，如果用多块共享内存，又存在子进程发送结果通知信号时，父进程收到信号后，不知道是谁发送，也意味着不知道该访问哪块共享内存，即使子进程发送不同的结果通知信号，因为等待信号的一定是阻塞的，如果某个子进程意外终止，父进程将永远阻塞下去，而不能超时处理

3 采用信号量或者msgctl自己的加锁、解锁功能，不过后者只适用于linux

==============================================================================

1.管道（pipe）及有名管道（named pipe）：
管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。
管道是单向的、先进先出的、无结构的、固定大小的字节流，它把一个进程的标准输出和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的道端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。

==============================================================================

2.信号（signal）：
信号是在软件层次上对中断机制的一种模拟，它是比较复杂的通信方式，用于通知进程有某事件发生，一个进程收到一个信号与处理器收到一个中断请求效果上可以说是一致的。
信号是在软件层次上对中断机制的一种模拟，是一种异步通信方式。
SIGINT：在键盘按下<Ctrl+C>组合键后产生，默认动作为终止进程
SIGQUIT：在键盘按下<Ctrl+\>组合键后产生，默认动作为终止进程
SIGKILL：无条件终止进程。本信号不能被忽略、处理和阻塞。默认动作为终止进程。
它向系统管理员提供了一种可以杀死任何进程的方法
SIGALRM：定时器超时，超时的时间由系统调用alarm设置。默认动作为终止进程
SIGCHLD：子进程结束时，父进程会收到这个信号。默认动作为忽略该信号

程序可以用signal库函数来处理信号，它的定义如下:
#include <signal.h>
void (*signal(int sig, void (*func)(int)))(int);
signal函数作用是绑定信号值为sig的信号的响应时间为func指向的函数，即当捕获到sig信号时，调用func指向的函数(可称为信号处理函数)，另外func也可以用下面两个特殊值之一来代替信号处理函数：
SIG_IGN    忽略信号
SIG_DFL    恢复默认行为

信号种类
把那些建立在早期机制上的信号叫做"不可靠信号"，信号值小于SIGRTMIN(Red hat 7.2中，SIGRTMIN=32，SIGRTMAX=63)的信号都是不可靠信号。
进程每次处理信号后，就将对信号的响应设置为默认动作。在某些情况下，将导致对信号的错误处理；因此，用户如果不希望这样的操作，那么就要在信号处理函数结尾再一次调用signal()，重新安装该信号。

信号可能丢失，后面将对此详细阐述。 如果在进程对某个信号进行处理时，这个信号发生多次，对后到来的这类信号不排队，那么仅传送该信号一次，即发生了信号丢失。

Linux支持不可靠信号，但是对不可靠信号机制做了改进：在调用完信号处理函数后，不必重新调用该信号的安装函数（信号安装函数是在可靠机制上的实现）。因此，Linux下的不可靠信号问题主要指的是信号可能丢失。

信号值位于SIGRTMIN和SIGRTMAX之间的信号都是可靠信号，可靠信号克服了信号可能丢失的问题。
1 ~ 31的信号为传统UNIX支持的信号，是不可靠信号(非实时的)，后32个信号表示实时信号，等同于前面阐述的可靠信号。
非实时信号都不支持排队，都是不可靠信号；实时信号都支持排队，都是可靠信号。

不可靠信号是信号值小于SIGRTMIN的信号。信号的可靠与不可靠只与信号值有关，与信号的发送及安装函数无关。目前linux中的signal()是通过sigation()函数实现的，因此，即使通过signal（）安装的信号，在信号处理函数的结尾也不必再调用一次信号安装函数。同时，由signal()安装的实时信号支持排队，同样不会丢失。

后32个信号表示实时信号，等同于前面阐述的可靠信号。这保证了发送的多个实时信号都被接收。

信号的产生
1)由硬件产生，如从键盘输入Ctrl+C可以终止当前进程
2)由其他进程发送，如可在shell进程下，使用命令 kill -信号标号 PID，向指定进程发送信号。
3)异常，进程异常时会发送信号

信号的处理
发送信号的主要函数有：kill()、raise()、 sigqueue()、alarm()、setitimer()以及abort()。
信号是由操作系统来处理的，说明信号的处理在内核态。
信号不一定会立即被处理，此时会储存在信号的信号表中。
可以用kill命令给某个进程发送信号，如果不明确指定信号则发送SIGTERM信号，该信号的默认处理动作是终止进程。

阻塞信号
原型：
int sigprocmask(int how,const sigset_t *set,sigset_t *oset);
how:设置block阻塞表的方式
a.SIG_BLOCK:将信号集添加到block表中
b.SIG_UNBLOCK:将信号集从block表中删除
c.SIG_SETMASK：将信号集设置为block表
set:要设置的集合
oset:设置前保存之前block表信息
如果该进程当前并未处于执行态，则该信号就由内核保存起来，直到该进程恢复执行再传递个它；如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞取消时才被传递给进程。

获取未决信号
前面已经讲过，阻塞的信号处于未决的状态，会放入进程的未决信号表。
原型：
int sigpending(sigset_t *set);
set:out型参数，会将获得的当前进程的pending未决表中的信号集传入。

==============================================================================

3.消息队列（message queue）：
所谓消息队列，其实就是消息(数据)传输过程中保存的容器
消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息。

匿名管道以及命名管道是随进程的，进程的退出，意味着管道生命周期的结束；
其次，管道传送数据时以无格式字节流的形式传送，这有时会给程序的开发带来不便；
再者，担当数据传送媒介的管道，其缓冲区的大小也有较大的限制。
较管道来说，消息队列的生命周期更加持久。消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。 
消息队列是基于消息的， 而管道是基于字节流的，且消息队列的读取不一定是先入先出。消息队列与命名管道有一 样的不足，就是每个消息的最大长度是有上限的（MSGMAX），每个消息队列的总的字节数是有上限的（MSGMNB），系统上消息队列的总数也有一个上限（MSGMNI）
消息队列的数据结构（struct ipc_ids msg_ids）位于内核中，系统中的所有消息队列都可以在结构msg_ids中找到访问入口。 
消息队列就是一个消息的链表。
每个消息队列都有一个队列头，用结构struct msg_queue来描述。
队列头中包含了该消息队列的大量信息，包括消息队列键值、用户ID、组ID、消息队列中消息数目等等，甚至记录了最近对消息队列读写进程的ID。
读者可以访问这些信息，也可以设置其中的某些信息。

接受消息的时候
msgtyp等于0，则返回队列的最早的一个消息。
msgtyp大于0，则返回其类型为mtype的第一个消息。
msgtyp小于0，则返回其类型小于或等于mtype参数的绝对值的最小的一个消息。

使用msgget()函数创建打开队列；
int msgget(key_t key,int msgflg)
key为键值，可设置成常数IPC_PRIVATE，或由ftok获取；key_t ftok(char *pathname,char proj)

使用msgrcv()函数从队列中读数据；
int msgsnd(int msqid,struct msgbuf *msgp,size_t msgz,int msgflg)
sqid为消息队列ID，由内核反馈；
msgp：指向消息缓冲区的指针，此位置用来暂时存储发送和接收的消息，是一个用户可定义的通用结构；

使用msgsnd()函数写数据到队列中；
使用msgctl()函数控制消息队列；
int main()  
{  
    int running = 1;  
    int msgid = -1;  
    struct msg_st data;  
    long int msgtype = 0; //注意1  
  
    //建立消息队列  
    msgid = msgget((key_t)1234, 0666 | IPC_CREAT);  
    if(msgid == -1)  
    {  
        fprintf(stderr, "msgget failed with error: %d\n", errno);  
        exit(EXIT_FAILURE);  
    }  
    //从队列中获取消息，直到遇到end消息为止  
    while(running)  
    {  
        if(msgrcv(msgid, (void*)&data, BUFSIZ, msgtype, 0) == -1)  
        {  
            fprintf(stderr, "msgrcv failed with errno: %d\n", errno);  
            exit(EXIT_FAILURE);  
        }  
        printf("You wrote: %s\n",data.text);  
        //遇到end结束  
        if(strncmp(data.text, "end", 3) == 0)  
            running = 0;  
    }  
    //删除消息队列  
    if(msgctl(msgid, IPC_RMID, 0) == -1)  
    {  
        fprintf(stderr, "msgctl(IPC_RMID) failed\n");  
        exit(EXIT_FAILURE);  
    }  
    exit(EXIT_SUCCESS);  
}  
==============================================================================
    msgid = msgget((key_t)1234, 0666 | IPC_CREAT);  
    if(msgid == -1)  
    {  
        fprintf(stderr, "msgget failed with error: %d\n", errno);  
        exit(EXIT_FAILURE);  
    }  
  
    //向消息队列中写消息，直到写入end  
    while(running)  
    {  
        //输入数据  
        printf("Enter some text: ");  
        fgets(buffer, BUFSIZ, stdin);  
        data.msg_type = 1;    //注意2  
        strcpy(data.text, buffer);  
        //向队列发送数据  
        if(msgsnd(msgid, (void*)&data, MAX_TEXT, 0) == -1)  
        {
            fprintf(stderr, "msgsnd failed\n");  
            exit(EXIT_FAILURE);  
        }
        //输入end结束输入  
        if(strncmp(buffer, "end", 3) == 0)
            running = 0;  
        sleep(1);  
    }  
    exit(EXIT_SUCCESS);  
如果把注意1，即msgreceive.c文件main函数中的语句由long int msgtype = 0;改变为long int msgtype = 2;会发生什么情况，msgreceive将不能接收到程序msgsend发送的信息。因为在调用msgrcv函数时，如果msgtype（第四个参数）大于零，则将只获取具有相同消息类型的第一个消息，修改后获取的消息类型为2，而msgsend发送的消息类型为1，所以不能被msgreceive程序接收。

==============================================================================

4.共享内存（shared memory）：
可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。
总之，当一个程序想和另外一个程序通信的时候，那内存将会为这两个程序生成一块公共的内存区域。
这块被两个进程分享的内存区域叫做共享内存。
由于全部进程共享同一块内存，共享内存在各种进程间通信方式中具有最高的效率。

共享内存段紧靠在栈之下，最大限制为32M

共享内存的实现分为两个步骤:
创建共享内存，使用shmget函数。
映射共享内存。将这段创建的共享内存映射到详细的进程空间去，使用shmat函数。
key_t ftok(char *pathname,char proj);
共享内存映射
void *shmat(int shm_id, const void *shm_addr, int shmflg);
共享内存控制
int shmctl(int shm_id, int cmd, struct shmid_ds *buf);
共享内存分离 
int shmdt(const void *shm_addr);
创建共享内存 
int shmget(key_t key, size_t size, int shmflg);

（1）进程通过调用shmget（Shared Memory GET，获取共享内存）来分配一个共享内存块。
（2）要让一个进程获取对一块共享内存的访问，这个进程必须先调用 shmat（SHared Memory Attach，绑定到共享内存）。将 shmget 返回的共享内存标识符 SHMID 传递给这个函数作为第一个参数。该函数的第二个参数是一个指针，指向您希望用于映射该共享内存块的进程内存地址；如果您指定NULL则Linux会自动选择一个合适的地址用于映射。
（3）调用 shmctl（"Shared Memory Control"，控制共享内存）函数会返回一个共享内存块的相关信息。要删除一个共享内存块，则应将 IPC_RMID 作为第二个参数，而将 NULL 作为第三个参数。当最后一个绑定该共享内存块的进程与其脱离时，该共享内存块将被删除。

==============================================================================

共享内存的使用和实现原理

两个不同进程A、B共享内存的意思是，同一块物理内存被映射到进程A、B各自的进程地址空间

1、共享内存允许两个或更多进程共享一个给定的存储区，因为数据不需要再客户进程和服务进程之间复制。所以这是最快的一种ipc。

2、使用共享内存时需要注意：多个进程对共享内存的同步访问。

3、通常用信号量实现对共享内存的同步访问。
==============================================================================

5.信号量（semaphore）：
主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段。
P操作原语：
sem 减1
若sem 大于等于0，线程继续执行.
若sem < 0 ，线程进入阻塞队列.

V 操作原语：
sem加1
若sem 大于 0, 线程继续执行
若sem 小于等于0,唤醒阻塞队例的线程

信号量是一个特殊的变量，程序对其访问都是原子操作，且只允许对它进行等待（即P(信号变量))和发送（即V(信号变量))信息操作。最简单的信号量是只能取0和1的变量，这也是信号量最常见的一种形式，叫做二进制信号量。而可以取多个正整数的信号量被称为通用信号量。

信号量是一种特殊的变量，访问具有原子性。
只允许对它进行两个操作：
1)等待信号量
当信号量值为0时，程序等待；当信号量值大于0时，信号量减1，程序继续运行。
2)发送信号量
将信号量值加1。
我们使用信号量，来解决进程或线程间共享资源引发的同步问题。

int semget(key_t key,int num_sems,int sem_flags);
key:信号量键值，可以理解为信号量的唯一性标记。
num_sems:信号量的数目，一般为1
sem_flags:有两个值，IPC_CREATE和IPC_EXCL，
IPC_CREATE表示若信号量已存在，返回该信号量标识符。
IPC_EXCL表示若信号量已存在，返回错误。
返回值：相应的信号量标识符，失败返回-1

int semop(int sem_id,struct sembuf *sem_opa,size_t num_sem_ops);
sem_id:信号量标识符
sem_opa:结构如下
struct sembuf{  
    short sem_num;//除非使用一组信号量，否则它为0  
    short sem_op;//信号量在一次操作中需要改变的数据，通常是两个数，一个是-1，即P（等待）操作，  
                    //一个是+1，即V（发送信号）操作。  
    short sem_flg;//通常为SEM_UNDO,使操作系统跟踪信号，  
                    //并在进程没有释放该信号量而终止时，操作系统释放信号量  
}; 

int semctl(int sem_id,int sem_num,int command,[union semun sem_union]);
command:有两个值SETVAL,IPC_RMID，分别表示初始化和删除信号量。
sem_union:可选参数，结构如下：
union semun{  
    int val; 
    struct semid_ds *buf;  
    unsigned short *arry;  
}; 
一般用到的是val,表示要传给信号量的初始值。

==============================================================================

等待线程：
pthread_cond_wait前要先加锁
pthread_cond_wait内部会解锁，然后等待条件变量被其它线程激活
pthread_cond_wait被激活后会再自动加锁

激活线程：
加锁（和等待线程用同一个锁）
pthread_cond_signal发送信号（阶跃信号前最好判断有无等待线程）
     
解锁
激活线程的上面三个操作在运行时间上都在等待线程的pthread_cond_wait函数内部。

==============================================================================

6.套接字（socket）；
这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。

==============================================================================

管道与文件描述符,文件指针的关系? 
答: 其实管道的使用方法与文件类似,都能使用read,write,open等普通IO函数. 管道描述符类似于文件描述符. 事实上, 管道使用的描述符, 文件指针和文件描述符最终都会转化成系统中SOCKET描述符. 都受到系统内核中SOCKET描述符的限制. 本质上LINUX内核源码中管道是通过空文件来实现.

管道的使用方法? 
答: 主要有下面几种方法: 1)pipe, 创建一个管道,返回2个管道描述符.通常用于父子进程之间通讯. 2)popen, pclose: 这种方式只返回一个管道描述符,常用于通信另一方是stdin or stdout; 3)mkpipe: 命名管道, 在许多进程之间进行交互.

管道与系统IPC之间的优劣比较? 
答: 
管道: 优点是所有的UNIX实现都支持, 并且在最后一个访问管道的进程终止后,管道就被完全删除;缺陷是管道只允许单向传输或者用于父子进程之间.
系统IPC: 优点是功能强大,能在毫不相关进程之间进行通讯; 缺陷是关键字KEY_T使用了内核标识,占用了内核资源,而且只能被显式删除,而且不能使用SOCKET的一些机制,例如select,epoll等.

==============================================================================

Write函数

      Ssize_t write(int fd,const void*buf,size_t nbytes);

      Write函数将buf中的nbytes字节内容写入到文件描述符中，成功返回写的字节数，失败返回-1.并设置errno变量。在网络程序中，当我们向套接字文件描述舒服写数据时有两种可能：

      1、write的返回值大于0，表示写了部分数据或者是全部的数据，这样用一个while循环不断的写入数据，但是循环过程中的buf参数和nbytes参数是我们自己来更新的，也就是说，网络编程中写函数是不负责将全部数据写完之后再返回的，说不定中途就返回了！

      2、返回值小于0，此时出错了，需要根据错误类型进行相应的处理。

      如果错误是EINTR表示在写的时候出现了中断错误，如果是EPIPE表示网络连接出现了问题。

Read函数

      Ssize_t read(int fd,void*buf,size_t nbyte)

      Read函数是负责从fd中读取内容，当读取成功时，read返回实际读取到的字节数，如果返回值是0，表示已经读取到文件的结束了，小于0表示是读取错误。

      如果错误是EINTR表示在写的时候出现了中断错误，如果是EPIPE表示网络连接出现了问题。

      虽然写了100个字节，但并不能保证read一次即读100个字节，写的时候也并非写100就成功了，write和read实际成功读写的字节数由返回值确定。

==============================================================================

临界资源
  临界资源是一次仅允许一个进程使用的共享资源。各进程采取互斥的方式，实现共享的资源称作临界资源。属于临界资源的硬件有，打印机，磁带机等；软件有消息队列，变量，数组，缓冲区等。诸进程间采取互斥方式，实现对这种资源的共享。

临界区：
  每个进程中访问临界资源的那段代码称为临界区（criticalsection），每次只允许一个进程进入临界区，进入后，不允许其他进程进入。不论是硬件临界资源还是软件临界资源，多个进程必须互斥的对它进行访问。多个进程涉及到同一个临界资源的的临界区称为相关临界区。使用临界区时，一般不允许其运行时间过长，只要运行在临界区的线程还没有离开，其他所有进入此临界区的线程都会被挂起而进入等待状态，并在一定程度上影响程序的运行性能。

==============================================================================

多线程如何同步：

临界区、互斥区、事件、信号量四种方式

==============================================================================

临界区（Critical Section）、互斥量（Mutex）、信号量（Semaphore）、事件（Event）的区别
1）、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。

2）、互斥量：采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享，还能实现不同应用程序的公共资源安全共享 .互斥量比临界区复杂。因为使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。

3）、信号量：它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目 .信号量对象对线程的同步方式与前面几种方法不同，信号允许多个线程同时使用共享资源，这与操作系统中的PV操作相同。它指出了同时访问共享资源的线程最大数目。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。

PV操作及信号量的概念都是由荷兰科学家E.W.Dijkstra提出的。信号量S是一个整数，S大于等于零时代表可供并发进程使用的资源实体数，但S小于零时则表示正在等待使用共享资源的进程数。
　　 P操作申请资源：
　　（1）S减1；
　　（2）若S减1后仍大于等于零，则进程继续执行；
　　（3）若S减1后小于零，则该进程被阻塞后进入与该信号相对应的队列中，然后转入进程调度。
　　
　　V操作 释放资源：
　　（1）S加1；
　　（2）若相加结果大于零，则进程继续执行；
　　（3）若相加结果小于等于零，则从该信号的等待队列中唤醒一个等待进程，然后再返回原进程继续执行或转入进程调度。
4）、事 件： 通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作 .

总结：
　　1） 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说它可以跨越进程使用。所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。
　　2） 互斥量（Mutex），信号灯（Semaphore），事件（Event）都可以被跨越进程使用来进行同步数据操作，而其他的对象与数据同步操作无关，但对于进程和线程来讲，如果进程和线程在运行状态则为无信号状态，在退出后为有信号状态。所以可以使用WaitForSingleObject来等待进程和线程退出。
　　3） 通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号灯对象可以说是一种资源计数器。

==============================================================================

信号量和互斥体之间的区别

概念上的区别：

信号量：是进程间（线程间）同步用的，一个进程（线程）完成了某一个动作就通过信号量告诉别的进程（线程），别的进程（线程）再进行某些动作。有二值和多值信号量之分。

互斥锁：是线程间互斥用的，一个线程占用了某一个共享资源，那么别的线程就无法访问，直到这个线程离开，其他的线程才开始可以使用这个共享资源。可以把互斥锁看成二值信号量。

上锁时：

信号量: 只要信号量的value大于0，其他线程就可以sem_wait成功，成功后信号量的value减一。若value值不大于0，则sem_wait阻塞，直到sem_post释放后value值加一。一句话，信号量的value>=0。

互斥锁: 只要被锁住，其他任何线程都不可以访问被保护的资源。如果没有锁，获得资源成功，否则进行阻塞等待资源可用。一句话，线程互斥锁的vlaue可以为负数。

使用场所： 
信号量主要适用于进程间通信，当然，也可用于线程间通信。而互斥锁只能用于线程间通信。

多线程的条件变量
条件变量是利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待"条件变量的条件成立"而挂起；另一个线程使"条件成立"（给出条件成立信号）。
为了防止竞争，条件变量的使用总是和一个互斥锁结合在一起。

pthread_mutex_lock
    xxxxxxx
pthread_cond_signal
pthread_mutex_unlock
缺点：在某下线程的实现中，会造成等待线程从内核中唤醒（由于cond_signal)然后又回到内核空间（因为cond_wait返回后会有原子加锁的 行为），所以一来一回会有性能的问题。但是在LinuxThreads或者NPTL里面，就不会有这个问题，因为在Linux 线程中，有两个队列，分别是cond_wait队列和mutex_lock队列， cond_signal只是让线程从cond_wait队列移到mutex_lock队列，而不用返回到用户空间，不会有性能的损耗。
所以在Linux中推荐使用这种模式。

pthread_mutex_lock
    xxxxxxx
pthread_mutex_unlock
pthread_cond_signal
优点：不会出现之前说的那个潜在的性能损耗，因为在signal之前就已经释放锁了
缺点：如果unlock和signal之前，有个低优先级的线程正在mutex上等待的话，那么这个低优先级的线程就会抢占高优先级的线程（cond_wait的线程)，而这在上面的放中间的模式下是不会出现的。

pthread_cond_wait()所做的第一件事就是同时对互斥对象解锁（于是其它线程可以修改已链接列表），并等待条件 mycond 发生（这样当 pthread_cond_wait() 接收到另一个线程的“信号”时，它将苏醒）。现在互斥对象已被解锁，其它线程可以访问和修改已链接列表
实际上，pthread_cond_wait()苏醒后将执行最后一个操作：重新锁定 mymutex。一旦 pthread_cond_wait() 锁定了互斥对象，那么它将返回并允许 1 号线程继续执行。那时，它可以马上检查列表，查看它所感兴趣的更改。
//生产者
void *product_run(void *arg)  
{  
  
    while(1)  
    {  
        //加锁 
        pthread_mutex_lock(&mylock);  
        /***
            生产动作
         ***/
        pthread_cond_signal(&mycond); //生产完毕后发出信号，唤醒其他被阻塞的线程
        pthread_mutex_unlock(&mylock); //解锁  
 
        printf("product is done,data=%d\n",data);  
    }  
}  

//消费者
void *consumer_run(void *arg)  
{  
    int data=0;  
    Node *head=(Node *)arg;  
    while(1)  
    {  
        pthread_mutex_lock(&mylock);  
        while(IsEmpty(head))  
        {  
            pthread_cond_wait(&mycond,&mylock);  
        }  
        PopFront(head,&data);  
        pthread_mutex_unlock(&mylock);  
        printf("consumer is done,data=%d\n",data);  
    }  
}  

==============================================================================
In Thread1:
pthread_mutex_lock(&m_mutex);   
pthread_cond_wait(&m_cond,&m_mutex);   
pthread_mutex_unlock(&m_mutex);  

In Thread2:
pthread_mutex_lock(&m_mutex);   
pthread_cond_signal(&m_cond);   
pthread_mutex_unlock(&m_mutex);  

为什么要与pthread_mutex 一起使用呢？ 这是为了应对 线程1在调用pthread_cond_wait()但线程1还没有进入wait cond的状态的时候，此时线程2调用了 cond_singal 的情况。 如果不用mutex锁的话，这个cond_singal就丢失了。加了锁的情况是，线程2必须等到 mutex 被释放（也就是 pthread_cod_wait() 释放锁并进入wait_cond状态 ，此时线程2上锁） 的时候才能调用cond_singal.
==============================================================================

信号与信号量的区别：
1.信号：（signal）是一种处理异步事件的方式。信号时比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程外，还可以发送信号给进程本身。linux除了支持unix早期的信号语义函数，还支持语义符合posix.1标准的信号函数sigaction。
2.信号量：（Semaphore）进程间通信处理同步互斥的机制。是在多线程环境下使用的一种设施, 它负责协调各个线程, 以保证它们能够正确、合理的使用公共资源。

==============================================================================

信号量/互斥体和自旋锁的区别

信号量/互斥体允许进程睡眠属于睡眠锁，自旋锁则不允许调用者睡眠，而是让其循环等待，所以有以下区别应用 
1）、信号量和读写信号量适合于保持时间较长的情况，它们会导致调用者睡眠，因而自旋锁适合于保持时间非常短的情况 
2）、自旋锁可以用于中断，不能用于进程上下文(会引起死锁)。而信号量不允许使用在中断中，而可以用于进程上下文 
3）、自旋锁保持期间是抢占失效的，自旋锁被持有时，内核不能被抢占，而信号量和读写信号量保持期间是可以被抢占的

另外需要注意的是 
1）、信号量锁保护的临界区可包含可能引起阻塞的代码，而自旋锁则绝对要避免用来保护包含这样代码的临界区，因为阻塞意味着要进行进程的切换，如果进程被切换出去后，另一进程企图获取本自旋锁，死锁就会发生。 
2）、在你占用信号量的同时不能占用自旋锁，因为在你等待信号量时可能会睡眠，而在持有自旋锁时是不允许睡眠的。

==============================================================================

进程和线程的区别：

答：线程是指进程内的一个执行单元,也是进程内的可调度实体。与进程的区别:

(1)调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位。

(2)并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行。

(3)拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源.

(4)系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。

进程间 堆栈独立
线程间 共享堆，栈独立
一个线程挂掉，则进程就会挂掉
所以说多进程比多线程更健壮

==============================================================================

epoll与select的区别：

问题的引出，当需要读两个以上的I/O的时候，如果使用阻塞式的I/O，那么可能长时间的阻塞在一个描述符上面，另外的描述符虽然有数据但是不能读出来，这样实时性不能满足要求，大概的解决方案有以下几种：

1.使用多进程或者多线程，但是这种方法会造成程序的复杂，而且对与进程与线程的创建维护也需要很多的开销。（Apache服务器是用的子进程的方式，优点可以隔离用户）

2.用一个进程，但是使用非阻塞的I/O读取数据，当一个I/O不可读的时候立刻返回，检查下一个是否可读，这种形式的循环为轮询（polling），这种方法比较浪费CPU时间，因为大多数时间是不可读，但是仍花费时间不断反复执行read系统调用。

3.异步I/O（asynchronous I/O），当一个描述符准备好的时候用一个信号告诉进程，但是由于信号个数有限，多个描述符时不适用。

4.一种较好的方式为I/O多路转接（I/O multiplexing）（貌似也翻译多路复用），先构造一张有关描述符的列表（epoll中为队列），然后调用一个函数，直到这些描述符中的一个准备好时才返回，返回时告诉进程哪些I/O就绪。select和epoll这两个机制都是多路I/O机制的解决方案，select为POSIX标准中的，而epoll为Linux所特有的。

区别（epoll相对select优点）主要有三：

1.select的句柄数目受限，在linux/posix_types.h头文件有这样的声明：#define __FD_SETSIZE    1024  表示select最多同时监听1024个fd。而epoll没有，它的限制是最大的打开文件句柄数目。

2.epoll的最大好处是不会随着FD的数目增长而降低效率，在selec中采用轮询处理，其中的数据结构类似一个数组的数据结构，而epoll是维护一个队列，直接看队列是不是空就可以了。epoll只会对"活跃"的socket进行操作---这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有"活跃"的socket才会主动的去调用 callback函数（把这个句柄加入队列），其他idle状态句柄则不会，在这点上，epoll实现了一个"伪"AIO。但是如果绝大部分的I/O都是“活跃的”，每个I/O端口使用率很高的话，epoll效率不一定比select高（可能是要维护队列复杂）。

3.使用mmap加速内核与用户空间的消息传递。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的。

==============================================================================
epoll中et和lt的区别与实现原理：

epoll有2种工作方式:LT和ET。
LT(level triggered 水平触发)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件
描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你 的，所以，这种模式编程出错
误可能性要小一点。传统的select/poll都是这种模型的代表．

ET (edge-triggered 边缘触发)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核
通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述 符发送更多的就绪通知，直到你做了某些操作
导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致 了一个
EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only 
once),不过在TCP协议中，ET模式的加速效用仍需要更多的benchmark确认。
epoll只有epoll_create,epoll_ctl,epoll_wait 3个系统调用。

通常来说，et方式是比较危险的方式，如果要使用et方式，那么，应用程序应该 1、将socket设置为non-blocking方式 2、epoll_wait收到event后，read或write需要读到没有数据为止，write需要写到没有数据为止（对于non-blocking socket来说，EAGAIN通常是无数据可读，无数据可写的返回状态）；

==============================================================================

每一个epoll对象都有一个独立的eventpoll结构体，用于存放通过epoll_ctl方法向epoll对象中添加进来的事件。这些事件都会挂载在红黑树中，如此，重复添加的事件就可以通过红黑树而高效的识别出来(红黑树的插入时间效率是lgn，其中n为树的高度)。

而所有添加到epoll中的事件都会与设备(网卡)驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个回调方法。这个回调方法在内核中叫ep_poll_callback,它会将发生的事件添加到rdlist双链表中。

当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。

==============================================================================

等待epoll池中的socket发生事件，这里一般设置为阻塞的
events这个参数的类型是epoll_event类型的数组
如果epoll池中的一个或者多个socket发生事件，
epoll_wait就会返回，参数events中存放了发生事件的socket和这个socket所发生的事件
这里强调一点，epoll池存放的是一个个socket，不是一个个socket事件
一个socket可能有多个事件，epoll_wait返回的是有消息的socket的数目
如果epoll_wait返回事件数组后，下面的程序代码却没有处理当前socket发生的事件
那么epoll_wait将不会再次阻塞，而是直接返回，参数events里面的就是刚才那个socket没有被处理的事件

==============================================================================

ET模式下的accept
    考虑这种情况：多个连接同时到达，服务器的 TCP 就绪队列瞬间积累多个就绪

连接，由于是边缘触发模式，epoll 只会通知一次，accept 只处理一个连接，导致 TCP 就绪队列中剩下的连接都得不到处理。

     解决办法是用 while 循环抱住 accept 调用，处理完 TCP 就绪队列中的所有连接后再退出循环。如何知道是否处理完就绪队列中的所有连接呢？ accept  返回 -1 并且 errno 设置为 EAGAIN 就表示所有连接都处理完。 

的正确使用方式为： 

while ((conn_sock = accept(listenfd,(struct sockaddr *) &remote, (size_t *)&addrlen)) > 0) {   

    handle_client(conn_sock);   

}   

if (conn_sock == -1) {   

     if (errno != EAGAIN && errno != ECONNABORTED    

            && errno != EPROTO && errno != EINTR)    

        perror("accept");   

} 

==============================================================================

服务端使用多路转接技术（select，poll，epoll等）时，accept应工作在非阻塞模式。 

原因：如果accept工作在阻塞模式，考虑这种情况： TCP 连接被客户端夭折，即在服务器调用 accept 之前（此时select等已经返回连接到达读就绪），客户端主动发送 RST 终止连接，导致刚刚建立的连接从就绪队列中移出，如果套接口被设置成阻塞模式，服务器就会一直阻塞在 accept 调用上，直到其他某个客户建立一个新的连接为止。但是在此期间，服务器单纯地阻塞在accept 调用上（实际应该阻塞在select上），就绪队列中的其他描述符都得不到处理。

    解决办法是把监听套接口设置为非阻塞， 当客户在服务器调用 accept 之前中止

某个连接时，accept 调用可以立即返回 -1， 这时源自 Berkeley 的实现会在内核中处理该事件，并不会将该事件通知给 epoll，而其他实现把 errno 设置为 ECONNABORTED 或者 EPROTO 错误，我们应该忽略这两个错误。（具体可参看UNP v1 p363）

采用LT模式下，如果accept调用有返回就可以马上建立当前这个连接了，再epoll_wait等待下次通知，和select一样。

==============================================================================
但是对于ET而言，如果accpet调用有返回，除了建立当前这个连接外，不能马上就epoll_wait还需要继续循环accpet，直到返回-1，且errno==EAGAIN，

从本质上讲：与LT相比，ET模型是通过减少系统调用来达到提高并行效率的。
==============================================================================
linux下的锁
https://www.cnblogs.com/tgycoder/p/5442040.html

==============================================================================
send函数缓存问题
send()函数默认情况下会使用Nagle算法。Nagle算法通过将未确认的数据存入缓冲区直到积攒到一定数量一起发送的方法。来降低主机发送零碎小数据包的数目。所以假设send()函数发送数据过快的话，该算法会将一些数据打包后统一发出去。假设不了接这样的情况，接收端採会遇到看似非常奇怪的问题，比方成功recv()的次数与成功send()的次数不相等。在这中情况下，接收端能够通过recv()的返回值是否为0来推断发送端是否发送完成。

==============================================================================
Nagle算法：
是为了减少广域网的小分组数目，从而减小网络拥塞的出现；
该算法要求一个tcp连接上最多只能有一个未被确认的未完成的小分组，在该分组ack到达之前不能发送其他的小分组，tcp需要收集这些少量的分组，并在ack到来时以一个分组的方式发送出去；其中小分组的定义是小于MSS的任何分组；
该算法的优越之处在于它是自适应的，确认到达的越快，数据也就发哦送的越快；而在希望减少微小分组数目的低速广域网上，则会发送更少的分组；

设计规则如下：

　　（1）如果包长度达到最大报文长度（MSS，Maximum Segment Size），则允许发送；

　　（2）如果该包含有FIN，则允许发送；

　　（3）设置了TCP_NODELAY选项，则允许发送；

　　（4）未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送；

　　（5）上述条件都未满足，但发生了超时（一般为200ms），则立即发送。


关闭Nagle：
setsockopt(fd,IPPROTO_TCP,TCP_NODELAY,(char*)&flag,sizeof(flag));

==============================================================================
延迟ACK：
如果tcp对每个数据包都发送一个ack确认，那么只是一个单独的数据包为了发送一个ack代价比较高，所以tcp会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ack，如果在延迟ack定时器触发时候，发现ack尚未发送，则立即单独发送；
延迟ACK好处：
(1) 避免糊涂窗口综合症；
(2) 发送数据的时候将ack捎带发送，不必单独发送ack；
(3) 如果延迟时间内有多个数据段到达，那么允许协议栈发送一个ack确认多个报文段；

==============================================================================
当Nagle遇上延迟ACK：
试想如下典型操作，写-写-读，即通过多个写小片数据向对端发送单个逻辑的操作，两次写数据长度小于MSS，当第一次写数据到达对端后，对端延迟ack，不发送ack，而本端因为要发送的数据长度小于MSS，所以nagle算法起作用，数据并不会立即发送，而是等待对端发送的第一次数据确认ack；这样的情况下，需要等待对端超时发送ack，然后本段才能发送第二次写的数据，从而造成延迟；

由于有Nagle算法，如果发送端启用了Nagle算法，接收端启用了TCP Delayed Acknowledge。当发送端发起两次写一次读的时候，第一次写，由于TCP没有等待ACK，直接发出去了，而第二次写的时候，第一次写的ACK还没有接收到，从而等待；而接收端有Delayed Acknowledge机制，会等待40ms以提供合并多个ACK的机会。Nagle算法的使用在一些实时性要求比较高的场合，会引起一些问题。比如项目中设计的UI鼠标远程控制远端的机器时，发现远端的鼠标操作很卡顿，这是因为鼠标消息的发送端由于Nagle算法的默认开启，是有延迟的，

==============================================================================
如下场景考虑关闭Nagle算法：
(1) 对端不向本端发送数据，并且对延时比较敏感的操作；这种操作没法捎带ack；
(2) 如上写-写-读操作；对于此种情况，优先使用其他方式，而不是关闭Nagle算法：
--使用writev，而不是两次调用write，单个writev调用会使tcp输出一次而不是两次，只产生一个tcp分节，这是首选方法；
--把两次写操作的数据复制到单个缓冲区，然后对缓冲区调用一次write；
--关闭Nagle算法，调用write两次；有损于网络，通常不考虑；
setsockopt(fd,IPPROTO_TCP,TCP_NODELAY,(char*)&flag,sizeof(flag));

==============================================================================
库函数是语言本身的一部分，而系统函数是内核提供给应用程序的接口，属于系统的一部分。
函数库调用是语言或应用程序的一部分，而系统调用是操作系统的一部分。
用户应用程序访问并使用内核所提供的各种服务的途径即是系统调用。在内核和用户应用程序相交界的地方，内核提供了一组系统调用接口，通过这组接口，应用程序可以访问系统硬件和各种操作系统资源。 
1.系统调用是为了方便应用使用操作系统的接口，而库函数是为了方便人们编写应用程序而引出的，比如你自己编写一个函数其实也可以说就是一个库函数。
2.系统调用可以理解为内核提供给我们在用户态用的接口函数，可以认为是某种内核的库函数。
3.read就是系统调用,而fread就是C标准库函数.

==============================================================================

1.进程上下文：
（1）进程上文：其是指进程由用户态切换到内核态是需要保存用户态时cpu寄存器中的值，进程状态以及堆栈上的内容，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。
（2）进程下文：其是指切换到内核态后执行的程序，即进程运行在内核空间的部分。

2.中断上下文：
（1）中断上文：硬件通过中断触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。中断上文可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境（主要是当前被中断的进程环境。
（2）中断下文：执行在内核空间的中断服务程序。

==============================================================================

软中断由进程或线程产生，不会直接中断CPU
上半部指中断处理程序 -- 敲键盘
下半部指与中断有相关性，但是可以延后处理的任务 -- 网卡接收数据
中断对时间非常敏感，中断不能被相同类型的中断打断
下半部可以被中断打断

中断特性：对时间敏感 硬件相关 不能被相同类型的中断打断

下半部包括：软中断 tasklet 工作队列

软中断产生后并不是立即执行，软中断只能被硬件中断打断，软中断并发在多个CPU上，可以使用自旋锁保护数据结构

一种类型的tasklet只能运行在一个CPU上串行执行，多种类型的tasklet可运行在多个CPU上

工作队列允许睡眠和重新调度

软中断和tasklet不能被中断和睡眠
工作队列允许重新调度和睡眠
软中断是静态分配的，在内核编译好后就不能改变
tasklet可在运行时通过添加模块的方式动态改变

如果任务需要睡眠，使用工作队列
如果任务需要延时一定时间后再触发，使用工作队列，使用内核timer定时器
如果延后的任务需要在一个tick内被处理，则使用软中断或tasklet，因为软中断或tasklet可抢占普通进程或线程同时不睡眠
如果延后任务对延时时间没有要求，使用工作队列，这些任务通常为无关紧要的任务

==============================================================================

内核运行在最高级别（内核态），这个级别几乎可以使用处理器的所有资源，而应用程序运行在较低级别（用户态），在这个级别的用户不能对硬件进行直接访问以及对内存的非授权访问。内核态和用户态有自己的内存映射，即自己的地址空间。

当工作在用户态的进程想访问某些内核才能访问的资源时，必须通过系统调用或者中断切换到内核态，由内核代替其执行。进程上下文和中断上下文就是完成这两种状态切换所进行的操作总称。我将其理解为保存用户空间状态是上文，切换后在内核态执行的程序是下文。

==============================================================================

1.进程上下文主要是异常处理程序和内核线程。内核之所以进入进程上下文是因为进程自身的一些工作需要在内核中做。例如，系统调用是为当前进程服务的，异常通常是处理进程导致的错误状态等。

2.中断上下文是由于硬件发生中断时会触发中断信号请求，请求系统处理中断，执行中断服务子程序。

==============================================================================
进程切换分两步
1.切换页目录以使用新的地址空间。
2.切换内核栈和硬件上下文。

对于linux来说，线程和进程的最大区别就在于地址空间。
对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。所以明显是进程切换代价大

线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor’s Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题

==============================================================================
ulimit -a |grep "open files"
进程可以的最多的文件
open files     (-n) 1024
==============================================================================

调度策略SCHED_OTHER, SCHED_IDLE, SCHED_BATCH，其调度优先级sched_priority是不起作用的，即可以看成其调度优先级为0；调度策略SCHED_FIFO和SCHED_RR是实时策略，他们的调度值范围是1到99，数值越大优先级越高，另外实时调度策略的线程总是比前面三种通常的调度策略优先级更高。

所有的调度都是抢占式的：如果一个具有更高静态优先级的线程转换为可以运行了，那么当前运行的线程会被强制进入其等待的队列中。

    SCHED_OTHER：该策略是是默认的Linux分时调度（time-sharing scheduling）策略，它是Linux线程默认的调度策略。SCHED_OTHER策略的静态优先级总是为0，对于该策略列表上的线程，调度器是基于动态优先级（dynamic priority）来调度的，动态优先级是跟nice中相关(nice值可以由接口nice, setpriority,sched_setattr来设置)，该值会随着线程的运行时间而动态改变，以确保所有具有SCHED_OTHER策略的线程公平运行。在Linux上，nice值的范围是-20到+19，默认值为0；nice值越大则优先级越低，相比高nice值（低优先级）的进程，低nice值（高优先级）的进程可以获得更多的处理器时间。使用命令ps -el查看系统的进程列表，其中NI列就是进程对应的nice值；使用top命令，看到的NI列也是nice值。运行命令的时候可用nice –n xx cmd来调整cmd任务的nice值，xx的范围是-20~19之间。

    SCHED_FIFO：先入先出调度策略（First in-first out scheduling）。该策略简单的说就是一旦线程占用cpu则一直运行，一直运行直到有更高优先级任务到达或自己放弃。

   SCHED_RR：时间片轮转调度(Round-robin scheduling)。该策略是SCHED_FIFO基础上改进来的，他给每个线程增加了一个时间片限制，当时间片用完后，系统将把该线程置于队列末尾。放在队列尾保证了所有具有相同优先级的RR任务的调度公平。

使用top命令，如果PR列的值为RT，则说明该进程采用的是实时策略，即调度策略是SCHED_FIFO或者为SCHED_RR，而对于非实时调度策略（比如SCHED_OTHER）的进程，该列的值是NI+20，以供Linux内核使用。
可以通过命令：
    ps -eo state,uid,pid,ppid,rtprio,time,comm
来查看进程对应的实时优先级（位于RTPRIO列下），如果有进程对应的列显示“-”，则说明它不是实时进程。注意任何实时策略进程的优先级都高于普通的进程，也就说实时优先级和nice优先级处于互不相交的两个范畴。

    I）线程默认的调度策略为SCHED_OTHER，并且最大和最小调度优先级都是0。

    II）调度策略SCHED_FIFO和SCHED_RR的优先级范围为1到99，并且初始设置时对应的调度优先级初始值为0。

    在Linux中，调度程序是一个叫schedule()的函数，该函数调用的频率很高，由它来决定是否要执行进程的切换，如果要切换的话，切换到那个进程等。那么在Linux中，在什么情况下要执行这个调度程序呢？我们把这种情况叫作调度时机。Linux调度时机主要有:

   I）进程状态转换的时刻：进程终止、进程睡眠（比如I/O阻塞就会导致这种情况），还比如进程调用sleep()或exit()等函数进行状态转换。 

   II）当前进程的时间片用完时。

   III）设备驱动程序，当设备驱动程序执行长而重复的任务时，在每次反复循环中，驱动程序读检查是否需要调度，如果必要，则调用调度程序schedule()放弃CPU。

   IV）进程从中断、异常及系统调用返回到用户态时。

#include <sched.h>  
int sched_setaffinity(pid_t pid,   
                      size_t cpusetsize,const cpu_set_t *mask);  
该接口可以用来设置线程的CPU亲和性（CPU affinity），设置线程的亲和性可以使得线程绑定到一个或多个指定的CPU上运行。
在多处理器系统上，设置CPU亲和性可以提高性能（主要原因是尽可能避免了cache失效和切换到其他CPU的消耗）。


通过fork创建的子进程继承父进程的CPU亲和性，通过 execve()后，亲和性仍然保持不变。我们可以下面命令来查看多核cpu的负载：

    I)cat /proc/cpuinfo  查看所有cpu的信息；

    II）top命令，然后再输入1，则显示多个cpu的使用信息；

    III）top命令，然后按下f，进入top Current Fields设置页面，然后按下j，表示要求显示进程使用那个cpu，回车后，回到刚才界面，此时P 显示此进程使用哪个CPU。
==============================================================================

针对多线程程序来说，为了防止每个线程占用过多内存， 它们会被规定一个最大栈空间，
如果用户程序没有显式指定大小的话， 系统就会分配一个缺省值，这个值在不同的平台可能会
不一样，比如x86系统往往是10M, MIPS可能是8M, ARM一般是4M或者2M, 可以用ulimit命令查到。
但有一点需要注意，这个查到的栈空间是子线程的，主线程往往会比这个值大很多,
所以栈溢出一般都发生在子线程中。
由于有了栈溢出的风险， 所以大空间的局部变量，alloca的参数过大都是要避免的，
如果非得要用大内存，就请考虑堆空间吧！

==============================================================================
Linux下，线程和进程区别不大，都有task_struct进程描述符。多线程进程可以看作是几个共享地址空间的进程的集合。但多线程一定是由一个主线程开始，这个主线程启动其他线程。主线程的线程栈在内核空间位置附近，大小为8MB，其他线程的线程栈是主线程在调用pthread_create创建线程时，由mmap分配的，所以这些线程栈在mmap的区域内，跟共享库入口同属一个区域，phtread_t tid中存储的就是线程结构体在mmap区域中的入口。普通线程栈的默认大小也是8MB，但是因为是动态分配的，所以可以在线程属性设置函数中调整线程栈的大小（主线程也可以修改栈大小）。线程中声明的局部变量在线程的数据结构体中，当然在mmap分配的区域中。可以比较这些变量的地址和tid中存储的值。

mmap的映射区域在堆和栈之间，起始地址从接近堆的低地址开始。

对于 Linux 进程或者说主线程，其 stack 是在 fork 的时候生成的，实际上就是复制了父亲的 stack 空间地址，然后写时拷贝 (cow) 以及动态增长。然而对于主线程生成的子线程而言，其 stack 将不再是这样的了，而是事先固定下来的，使用 mmap 系统调用，它不带有 VM_STACK_FLAGS 标记
==============================================================================

创建一个线程默认的状态是joinable, 如果一个线程结束运行但没有被join,则它的状态类似于进程中的Zombie Process,即还有一部分资源没有被回收（退出状态码），所以创建线程者应该调用pthread_join来等待线程运行结束，并可得到线程的退出代码，回收其资源（类似于wait,waitpid)
但是调用pthread_join(pthread_id)后，如果该线程没有运行结束，调用者会被阻塞，在有些情况下我们并不希望如此，比如在Web服务器中当主线程为每个新来的链接创建一个子线程进行处理的时候，主线程并不希望因为调用pthread_join而阻塞（因为还要继续处理之后到来的链接），这时可以在子线程中加入代码
pthread_detach(pthread_self()) 
或者父线程调用 
pthread_detach(thread_id)（非阻塞，可立即返回） 
这将该子线程的状态设置为detached,则该线程运行结束后会自动释放所有资源。

==============================================================================
Linux上进程有5种状态: 
1. 运行(正在运行或在运行队列中等待) 
2. 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 
3. 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 
4. 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 
5. 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行)

Linux进程状态：R (TASK_RUNNING)，可执行状态。
只有在该状态的进程才可能在CPU上运行。而同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。
很多操作系统教科书将正在CPU上执行的进程定义为RUNNING状态、而将可执行但是尚未被调度执行的进程定义为READY状态，这两种状态在linux下统一为 TASK_RUNNING状态。

Linux进程状态：S (TASK_INTERRUPTIBLE)，可中断的睡眠状态。
处于这个状态的进程因为等待某某事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。
通过ps命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态（除非机器的负载很高）。毕竟CPU就这么一两个，进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU又怎么响应得过来。

Linux进程状态：D (TASK_UNINTERRUPTIBLE)，不可中断的睡眠状态。
D是处于TASK_UNINTERRUPTIBLE的进程，深度睡眠，不响应信号。一般只有等待非常关键的事件时，才把进程设为这个状态。
与TASK_INTERRUPTIBLE状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号。
绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。否则你将惊奇的发现，kill -9竟然杀不死一个正在睡眠的进程了！于是我们也很好理解，为什么ps命令看到的进程几乎不会出现TASK_UNINTERRUPTIBLE状态，而总是TASK_INTERRUPTIBLE状态。
而TASK_UNINTERRUPTIBLE状态存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。（参见《linux内核异步中断浅析》）
在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到。
linux系统中也存在容易捕捉的TASK_UNINTERRUPTIBLE状态。执行vfork系统调用后，父进程将进入TASK_UNINTERRUPTIBLE状态，直到子进程调用exit或exec（参见《神奇的vfork》）。
通过下面的代码就能得到处于TASK_UNINTERRUPTIBLE状态的进程：
#include   void main() {  if (!vfork()) sleep(100);  }
然后我们可以试验一下TASK_UNINTERRUPTIBLE状态的威力。不管kill还是kill -9，这个TASK_UNINTERRUPTIBLE状态的父进程依然屹立不倒。

Linux进程状态：T (TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态。
向进程发送一个SIGSTOP信号，它就会因响应该信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。（SIGSTOP与SIGKILL信号一样，是非常强制的。不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数。）
向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。
当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。
对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。
而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。

Linux进程状态：Z (TASK_DEAD - EXIT_ZOMBIE)，退出状态，进程成为僵尸进程。
进程在退出的过程中，处于TASK_DEAD状态。
在这个退出过程中，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外。于是进程就只剩下task_struct这么个空壳，故称为僵尸。
之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在shell中，$?变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。
当然，内核也可以将这些信息保存在别的地方，而将task_struct结构释放掉，以节省一些空间。但是使用task_struct结构更为方便，因为在内核中已经建立了从pid到task_struct查找关系，还有进程间的父子关系。释放掉task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。
父进程可以通过wait系列的系统调用（如wait4、waitid）来等待某个或某些子进程的退出，并获取它的退出信息。然后wait系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉。
子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来“收尸”。这个信号默认是SIGCHLD，但是在通过clone系统调用创建子进程时，可以设置这个信号。
通过下面的代码能够制造一个EXIT_ZOMBIE状态的进程：
#include   void main() {  if (fork())  while(1) sleep(100); }
只要父进程不退出，这个僵尸状态的子进程就一直存在。那么如果父进程退出了呢，谁又来给子进程“收尸”？
当进程退出的时候，会将它的所有子进程都托管给别的进程（使之成为别的进程的子进程）。托管给谁呢？可能是退出进程所在进程组的下一个进程（如果存在的话），或者是1号进程。所以每个进程、每时每刻都有父进程存在。除非它是1号进程。
1号进程，pid为1的进程，又称init进程。
linux系统启动后，第一个被创建的用户态进程就是init进程。它有两项使命：
1、执行系统初始化脚本，创建一系列的进程（它们都是init进程的子孙）；
2、在一个死循环中等待其子进程的退出事件，并调用waitid系统调用来完成“收尸”工作；
init进程不会被暂停、也不会被杀死（这是由内核来保证的）。它在等待子进程退出的过程中处于TASK_INTERRUPTIBLE状态，“收尸”过程中则处于TASK_RUNNING状态。

Linux进程状态：X (TASK_DEAD - EXIT_DEAD)，退出状态，进程即将被销毁。
而进程在退出过程中也可能不会保留它的task_struct。比如这个进程是多线程程序中被detach过的进程（进程？线程？参见《linux线程浅析》）。或者父进程通过设置SIGCHLD信号的handler为SIG_IGN，显式的忽略了SIGCHLD信号。（这是posix的规定，尽管子进程的退出信号可以被设置为SIGCHLD以外的其他信号。）
此时，进程将被置于EXIT_DEAD退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以EXIT_DEAD状态是非常短暂的，几乎不可能通过ps命令捕捉到。

==============================================================================

在linux中多进程的并发执行时，处理不当可能会出现 孤儿进程和僵尸进程；它们出现的情况如下：
1.孤儿进程出现在: 父进程先于子进程结束时。（当用ps -a 时，可以看到父进程已不在了，而子进程依旧在的情形）
2.僵尸进程出现在：子进程先于父进程结束，而父进程未用 wait（）或者waitpid(),来监听子进程的状态，使子进程的资源迟迟不能释放的情形；

如果父进程先退出,子进程还没退出那么子进程将被托孤给init进程,这时子进程的父进程就是init进程(1号进程)。

在Linux进程的状态中，僵尸进程是非常特殊的一种，它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出状态等信息供其他进程收集，除此之外，僵尸进程不再占有任何内存空间。它需要它的父进程来为它收尸，如果他的父进程没安装SIGCHLD信号处理函数调用wait或waitpid()等待子进程结束，又没有显式忽略该信号，那么它就一直保持僵尸状态，如果这时父进程结束了，那么init进程自动会接手这个子进程，为它收尸，它还是能被清除的。但是如果如果父进程是一个循环，不会结束，那么子进程就会一直保持僵尸状态，这就是为什么系统中有时会有很多的僵尸进程。

守护进程就是在后台运行,不与任何终端关联的进程,通常情况下守护进程在系统启动时就在运行,它们以root用户或者其他特殊用户(apache和postfix)运行,并能处理一些系统级的任务.习惯上守护进程的名字通常以d结尾(sshd),但这些不是必须的.
下面介绍一下创建守护进程的步骤
调用fork(),创建新进程,它会是将来的守护进程.
在父进程中调用exit,保证子进程不是进程组长
调用setsid()创建新的会话区
将当前目录改成跟目录(如果把当前目录作为守护进程的目录,当前目录不能被卸载他作为守护进程的工作目录)
将标准输入,标注输出,标准错误重定向到/dev/null

==============================================================================
子进程死后，会发送SIGCHLD信号给父进程，父进程收到此信号后，执行waitpid()函数为子进程收尸。就是基于这样的原理：就算父进程没有调用wait，内核也会向它发送SIGCHLD消息，而此时，尽管对它的默认处理是忽略，如果想响应这个消息，可以设置一个处理函数。

处理SIGCHLD信号并不是必须的。
但对于某些进程，特别是服务器进程往往在请求到来时生成子进程处理请求。
如果父进程不等待子进程结束，子进程将成为僵尸进程（zombie）从而占用系统资源。
如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。
在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。
signal(SIGCHLD,SIG_IGN);
这样，内核在子进程结束时不会产生僵尸进程。这一点与BSD4不同，BSD4下必须显式等待子进程结束才能释放僵尸进程
或者
用两次fork()，而且使紧跟的子进程直接退出，使得孙子进程成为孤儿进程，从而init进程将负责清除这个孤儿进程。

==============================================================================

多线程的那点儿事（之读写锁）
在编写多线程的时候，有一种情况是十分常见的。那就是，有些公共数据修改的机会比较少。相比较改写，它们读的机会反而高的多。通常而言，在读的过程中，往往伴随着查找的操作，中间耗时很长。给这种代码段加锁，会极大地降低我们程序的效率。那么有没有一种方法，可以专门处理这种多读少写的情况呢？有，那就是读写锁。
文章总结：
    （1）读写锁的优势只有在多读少写、代码段运行时间长这两个条件下才会效率达到最大化；
    （2）任何公共数据的修改都必须在锁里面完成；
    （3）读写锁有自己的应用场所，选择合适的应用环境十分重要；
    （4）编写读写锁很容易出错，朋友们应该多加练习；
    （5）读锁和写锁一定要分开使用，否则达不到效果。

读写锁应用的场合
　　我们有时会遇到对同一个内存区域如数组或者链表进行多线程读写的情况,一般来说有以下几种处理方式: 1.不加任何限制,多见于读取写入都很快的情况,但有时也会出现问题. 2.对读写函数都加以同步互斥,这下问题是没了,但效率也下去了,比如说两个读取线程不是非要排队进入不可. 3.使用读写锁,安全和效率都得到了解决,特别合适读线程多于写线程的情况.也就是下面将要展现的模式.

读写锁的意图
　　读写锁的本意是分别对读写状态进行互斥区分,有互斥时才加锁,否则放行.互斥的情况有: 1.读写互斥. 2.写写互斥. 不互斥的情况是:读读,这种情况不该加以限制. 程序就是要让锁对象知道当前读写状态,再根据情况对读写的线程进行锁定和解锁。

当有一个读线程在操作时，其它的写线程无法进行操作，读线程可以正常操作，互不干扰。
当有一个写线程在操作时，其它的读线程无法进行操作

小结
当多个线程试图对同一内容进行读写操作时适合使用读写锁。
请理解并记住ReadWriteLock类读写锁的写法.
读写锁相对于线程互斥的优势在于高效，它不会对两个读线程进行盲目的互斥处理，当读线程数量多于写线程尤其如此，当全是写线程时两者等效。

读写锁实际是一种特殊的自旋锁，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。这种锁相对于自旋锁而言，能提高并发性，因为在多处理器系统中，它允许同时有多个读者来访问共享资源，最大可能的读者数为实际的逻辑CPU数。写者是排他性的，一个读写锁同时只能有一个写者或多个读者（与CPU数相关），但不能同时既有读者又有写者。
==============================================================================
互斥锁 mutex：
在访问共享资源之前对进行加锁操作，在访问完成之后进行解锁操作。 
加锁后，任何其他试图再次加锁的线程会被阻塞，直到当前进程解锁。 
如果解锁时有一个以上的线程阻塞，那么所有该锁上的线程都被编程就绪状态， 
第一个变为就绪状态的线程又执行加锁操作，那么其他的线程又会进入等待。 
在这种方式下，只有一个线程能够访问被互斥锁保护的资源。

读写锁 rwlock（也叫作共享互斥锁：读模式共享，写模式互斥）：
读写锁有三种状态：读加锁状态、写加锁状态和不加锁状态 
一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。（这也是它能够实现高并发的一种手段） 
当读写锁在写加锁模式下，任何试图对这个锁进行加锁的线程都会被阻塞，直到写进程对其解锁。 
当读写锁在读加锁模式先，任何线程都可以对其进行读加锁操作，但是所有试图进行写加锁操作的线程都会被阻塞，直到所有的读线程都解锁。 
所以读写锁非常适合对数据结构读的次数远远大于写的情况。

如果严格按照上述读写锁的操作进行的话，那么当读者源源不断到来的时候，写者总是得不到读写锁，就会造成不公平的状态。 
一种避免这种不公平状态的方法是： 
当处于读模式的读写锁接收到一个试图对其进行写模式加锁操作时，便会阻塞后面对其进行读模式加锁操作的线程。 
这样等到已经加读模式的锁解锁后，写进程能够访问此锁保护的资源。

自旋锁spinlock：
自旋锁的使用模式和互斥锁很类似。 
只是在加锁后，有线程试图再次执行加锁操作的时候，该线程不会阻塞，而处于循环等待的忙等状态（CPU不能够做其他事情）。 
所以自旋锁适用的情况是：锁被持有的时间较短，而且进程并不希望在重新调度上花费太多的成本。
自旋锁是专为防止多处理器并发（实现保护共享资源）而引入的一种锁机制
自旋锁只有在内核可抢占或SMP（多处理器）的情况下才真正需要，在单CPU且不可抢占的内核下，自旋锁的所有操作都是空操作。

RCU锁（Read-Copy Update）：读-复制 更新
实际上是对读写锁的一种改进，同样是对读者线程和写者线程进行区别对待，只不过对待的方式是不同的。 
读写锁中只允许多个读者同时访问被保护的数据，但是在RCU中允许多个读者和多个写者同时访问被保护的资源。写者的同步开销则取决于使用的写者间同步机制，RCU并不对此进行支持。 
RCU中，读者不需要使用锁，要访问资源尽管访问就好了。 
RCU中，写者的同步开销比较大，要等到所有的读者都访问完成了才能够对被保护的资源进行更新。 
写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收器注册一个回调函数以便在适当的时机执行真正的修改操作。 
读者必须提供一个信号给写者以便写者能够确定数据可以被安全地释放或修改的时机。有一个专门的垃圾收集器来探测读者的信号，一旦所有的读者都已经发送信号告知它们都不在使用被RCU保护的数据结构，垃圾收集器就调用回调函数完成最后的数据释放或修改操作。 
写者要从链表中删除元素 B，它首先遍历该链表得到指向元素 B 的指针，然后修改元素 B 的前一个元素的 next 指针指向元素 B 的 next 指针指向的元素C，修改元素 B 的 next 指针指向的元素 C 的 prep 指针指向元素 B 的 prep指针指向的元素 A,在这期间可能有读者访问该链表，修改指针指向的操作是原子的，所以不需要同步，而元素 B 的指针并没有去修改，因为读者可能正在使用 B 元素来得到下一个或前一个元素。写者完成这些操作后注册一个回调函数以便在 grace period 之后删除元素 B，然后就认为已经完成删除操作。垃圾收集器在检测到所有的CPU不在引用该链表后，即所有的 CPU 已经经历了 quiescent state（上下文切换）,grace period（所有的CPU都经历了一次上下文切换） 已经过去后，就调用刚才写者注册的回调函数删除了元素 B。

适用于网络路由表的查询更新、设备状态表的维护、数据结构的延迟释放以及多径I/O设备的维护

==============================================================================

volatile的本意是“易变的” 因为访问寄存器要比访问内存单元快的多,所以编译器一般都会作减少存取内存的优化，但有可能会读脏数据。当要求使用volatile声明变量值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。精确地说就是，遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问；如果不使用valatile，则编译器将对所声明的语句进行优化。（简洁的说就是：volatile关键词影响编译器编译的结果，用volatile声明的变量表示该变量随时可能发生变化，与该变量有关的运算，不要进行编译优化，以免出错）

一个参数既可以是const还可以是volatile吗？
可以的，例如只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。
==============================================================================
线程安全性
如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。
或者说:一个类或者程序所提供的接口对于线程来说是原子操作或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题。
线程安全问题都是由全局变量及静态变量引起的。
若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。

==============================================================================
在/arch/x86/include/asm/page_64_types.h下有如下两行：

#define __START_KERNEL_map _AC(0xffffffff80000000, UL)
#define KERNEL_IMAGE_START _AC(0xffffffff80000000, UL)

这就是对空间大小的划分，在0xffffffff80000000之前的是给用户空间，在0xffffffff80000000之后的给内核空间，如果你现在手里有大约12G的内存想让内核态下可以使用大小10G的空间可以修改此值，将上面两句改为如下：

#define __START_KERNEL_map _AC(0xfffffffc00000000, UL)
#define KERNEL_IMAGE_START _AC(0xfffffffc00000000, UL)

然后，再将你的内核加载到连续的物理内存起始地址即可,这样内核就可以有16G寻址空间
物理地址分布情况可以查看e820的信息取得。

==============================================================================

死锁（Deadlock）的形成
打个比方，假设有P1和P2两个进程，都需要A和B两个资源，现在P1持有A等待B资源，而P2持有B等待A资源，两个都等待另一个资源而不肯释放资源，就这样无限等待中，这就形成死锁，这也是死锁的一种情况。给死锁下个定义，如果一组进程中每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的。


死锁产生的四个必要条件

互斥条件：资源是独占的且排他使用，进程互斥使用资源，即任意时刻一个资源只能给一个进程使用，其他进程若申请一个资源，而该资源被另一进程占有时，则申请者等待直到资源被占有者释放。

不可剥夺条件：进程所获得的资源在未使用完毕之前，不被其他进程强行剥夺，而只能由获得该资源的进程资源释放。

请求和保持条件：进程每次申请它所需要的一部分资源，在申请新的资源的同时，继续占用已分配到的资源。

循环等待条件：在发生死锁时必然存在一个进程等待队列{P1,P2,…,Pn},其中P1等待P2占有的资源，P2等待P3占有的资源，…，Pn等待P1占有的资源，形成一个进程等待环路，环路中每一个进程所占有的资源同时被另一个申请，也就是前一个进程占有后一个进程所深情地资源。 
以上给出了导致死锁的四个必要条件，只要系统发生死锁则以上四个条件至少有一个成立。事实上循环等待的成立蕴含了前三个条件的成立，似乎没有必要列出然而考虑这些条件对死锁的预防是有利的，因为可以通过破坏四个条件中的任何一个来预防死锁的发生。

下面说说那个检测方法，其实方法挺简单的。

有两个容器，一个用于保存线程正在请求的锁，一个用于保存线程已经持有的锁。每次加锁之前都会做如下检测:
1)检测当前正在请求的锁是否已经被其它线程持有,如果有，则把那些线程找出来
2)遍历第一步中返回的线程，检查自己持有的锁是否正被其中任何一个线程请求
 如果第二步返回真,表示出现了死锁

死锁预防
我们可以通过破坏死锁产生的4个必要条件来 预防死锁，由于资源互斥是资源使用的固有特性是无法改变的。

破坏“不可剥夺”条件：一个进程不能获得所需要的全部资源时便处于等待状态，等待期间他占有的资源将被隐式的释放重新加入到 系统的资源列表中，可以被其他的进程使用，而等待的进程只有重新获得自己原有的资源以及新申请的资源才可以重新启动，执行。

破坏”请求与保持条件“：第一种方法静态分配即每个进程在开始执行时就申请他所需要的全部资源。第二种是动态分配即每个进程在申请所需要的资源时他本身不占用系统资源。

破坏“循环等待”条件：采用资源有序分配其基本思想是将系统中的所有资源顺序编号，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程

==============================================================================
kill pid

kill pid和kill -s 15 pid含义一样，表示发送一个SIGTERM的信号给对应的程序。程序收到该信号后，将会发生以下事情，

1 程序立刻停止

2 程序释放相应资源后立刻停止

3 程序可能仍然继续运行

大部分程序在接收到SIGTERM信号后，会先释放自己的资源，然后再停止。但也有一些程序在收到信号后，做一些其他事情，并且这些事情是可以配置的。也就是说，SIGTERM多半是会被阻塞，忽略的。

kill -9 pid
kill -9 pid等于kill -s 9 pid，表示强制，尽快终止一个进程。多半admin会用这个命令。
两种信号不能被忽略SIGKILL，SIGSTOP
==============================================================================
fork与vfork的区别
1.vfork保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。

2.fork要拷贝父进程的进程环境；而vfork则不需要完全拷贝父进程的进程环境，在子进程没有调用exec和exit之前，子进程与父进程共享进程环境，相当于线程的概念，此时父进程阻塞等待。

如果创建子进程是为了调用exec执行一个新的程序的时候，就应该使用vfork
==============================================================================

线程调度是在进程中进行，在同一存储区内操作，而进程则在不同存储区操作，所以进程调度数度比线程慢

线程也有自己的资源，比如栈，私有数据等等。说他使用而不拥有资源指的是使用的是进程的打开文件句柄，进程的全局数据，进程的地址空间等等,这些都属于进程，而不属于线程，进程内个线程共享。 
进程切换比线程切换开销大是因为进程切换时要切页表，而且往往伴随着页调度，因为进程的数据段代码段要换出去，以便把将要执行的进程的内容换进来。本来进程的内容就是线程的超集。而且线程只需要保存线程的上下文（相关寄存器状态和栈的信息）就好了，动作很小
==============================================================================
pthread_exit()用于线程退出，可以指定返回值，以便其他线程通过pthread_join（）函数获取该线程的返回值。 
return是函数返回，只有线程函数return，线程才会退出。 
exit是进程退出，如果在线程函数中调用exit，进程中的所有函数都会退出！
==============================================================================
1. 互斥锁用于线程的互斥，信号量用于线程的同步；

这是两者的根本区别，也就是互斥和同步的区别

互斥：是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性，但互斥无法限制访问者对资源的访问顺序，即访问是无序的。 

同步：是指在互斥的基础上，这是大多数情况，通过其它机制实现访问者对资源的有序访问。

在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的，少数情况是指可以允许多个访问者同时访问资源。

2. 互斥量值只能为0/1，信号量值可以为非负整数。  

也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。

信号量可以实现多个同类资源的多线程互斥和同步。

当信号量为单值信号量时，也可以完成一个资源的互斥访问。

3. 互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。
==============================================================================
fork、vfork和clone三个系统调用都可以创建一个新进程，而且都是通过调用do_fork来实现进程的创建；
Linux是通过复制父进程来创建一个新进程，进程创建的大致框架就是：复制PCB，对复制的PCB进行修改、分配新的内核堆栈...

在fork()之后exec之前两个进程用的是相同的物理空间（内存区），先把页表映射关系建立起来，并不真正将内存拷贝。子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。当父进程中有更改相应段的行为发生时，如进程写访问，再为子进程相应的段分配物理空间，如果不是因为exec，内核会给子进程的数据段、堆栈段分配相应的物理空间（至此两者有各自的进程空间，互不影响），而代码段继续共享父进程的物理空间（两者的代码完全相同）。而如果是因为exec，由于两者执行的代码不同，子进程的代码段也会分配单独的物理空间。fork时子进程获得父进程数据空间、堆和栈的复制所以变量的地址（当然是虚拟地址）是一样的。

vfork是一个过时的应用，vfork也是创建一个子进程，但是子进程共享父进程的空间。在vfork创建子进程之后，父进程阻塞，直到子进程执行了exec()或者exit()。vfork最初是因为fork没有实现COW机制，而很多情况下fork之后会紧接着exec，而exec的执行相当于之前fork复制的空间全部变成了无用功，所以设计了vfork。而现在fork使用了COW机制，唯一的代价仅仅是复制父进程页表的代价，所以vfork不应该出现在新的代码之中。    
vfork()是共享内存

 clone是Linux为创建线程设计的（虽然也可以用clone创建进程）
clone和fork的区别：
（1） clone和fork的调用方式很不相同，clone调用需要传入一个函数，该函数在子进程中执行。
（2）clone和fork最大不同在于clone不再复制父进程的栈空间，而是自己创建一个新的。 （void *child_stack,）也就是第二个参数，需要分配栈指针的空间大小，所以它不再是继承或者复制，而是全新的创造。
==============================================================================
1、  获取Linux默认线程栈大小
ulimit -s

2、  修改Linux默认线程栈大小
ulimit -s value

（1）进程栈大小时执行时确定的，与编译链接无关
（2）进程栈大小是随机确认的，至少比线程栈要大，但不会超过2倍
（3）线程栈是固定大小的，可以使用ulimit -a 查看，使用ulimit -s 修改
（4）一般默认情况下，线程栈是在进程的堆中分配栈空间，每个线程拥有独立的栈空间，为了避免线程之间的栈空间踩踏，线程栈之间还会有以小块guardsize用来隔离保护各自的栈空间，一旦另一个线程踏入到这个隔离区，就会引发段错误

程序运行以后，我们可以通过/ proc/PID/task来看该程序有多少线程在运行
/proc/PID/maps就是进程的地址空间

程序的局部变量，用alloca分配的内存空间超出了栈空间的最大值，程序当然会死得很难看。
其实针对多线程程序来说，为了防止每个线程占用过多内存， 它们会被规定一个最大栈空间，
如果用户程序没有显式指定大小的话， 系统就会分配一个缺省值，这个值在不同的平台可能会
不一样，比如x86系统往往是10M, MIPS可能是8M, ARM一般是4M或者2M, 可以用ulimit命令查到。
但有一点需要注意，这个查到的栈空间是子线程的，主线程往往会比这个值大很多,
所以栈溢出一般都发生在子线程中。
由于有了栈溢出的风险， 所以大空间的局部变量，alloca的参数过大都是要避免的，
如果非得要用大内存，就请考虑堆空间吧！

==============================================================================
一个线程一个栈，一个进程一个堆
64位Linux下，默认一个线程栈的大小为8M
一个进程的堆的大小，理论上大概等于进程虚拟空间大小-内核虚拟内存大小。
Linux下，进程的高位1G留给内核，低位留给用户，所以进程堆大小小于低位的虚拟内存的大小。
实际使用中堆是动态分配增长的

进程栈空间从0xC0000000往下进行分配
运行时堆通过malloc进行分配,位置处于.bss与0x40000000之间
在Glibc的malloc中,对于小于128k的需求,直接从堆中分配,而大于128k的需求则通过mmap从文件映射区之后分配,因此地址会大于0x40000000.
因此,对于以LinuxThread实现的多线程而言,要区分以下两种情况:

管理线程,管理线程的堆栈与普通进程无异,即以上提到的三点
普通线程,因为管理线程会在进程堆中申请一块空间(THREAD_MANAGER_STACK_SIZE=8M?)当作自已的运行栈,
而我们知道,大于128k的malloc会采用mmap方式从文件映射区之后分配,所以,普通线程的栈地址就在这个空间内,即大于0x40000000
对于NPTL,因其不使用管理线程,因此,该进程中所有的线程都在小于0xC0000000的栈区,只不过,每个线程在这个大栈区使用不同的小块而已.

==============================================================================
valgrind --tool=memcheck --leak-check=full ./mem_leak
内存泄露检测工具valgrind
程序编译时一定要增加-g参数，以添加调试信息，这样memcheck的错误信息可以精确到行

Memcheck 能够检测出内存问题，关键在于其建立了两个全局表。
Valid-Value 表：
对于进程的整个地址空间中的每一个字节(byte)，都有与之对应的 8 个bits；对于 CPU 的每个寄存器，也有一个与之对应的bit 向量。这些 bits 负责记录该字节或者寄存器值是否具有有效的、已初始化的值。

Valid-Address 表
对于进程整个地址空间中的每一个字节(byte)，都有与之对应的 1 个bit，负责记录该地址是否能够被读写。
检测原理：
当要读写内存中某个字节时，首先检查这个字节对应的 A bit。如果该A bit显示该位置是无效位置，memcheck 则报告读写错误。

内核（core）类似于一个虚拟的 CPU 环境，这样当内存中的某个字节被加载到真实的 CPU 中时，该字节对应的 V bit 也被加载到虚拟的 CPU 环境中。一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则 memcheck 会检查对应的V bits，如果该值尚未初始化，则会报告使用未初始化内存错误。
==============================================================================
进程调用read或是write后会陷入内核，因为这两个函数都是系统调用，进入系统调用后，内核开始读写文件，假设内核在读取文件，内核首先把文件读入自己的内核空间，读完之后进程在内核回归用户态，内核把读入内核内存的数据再copy进入进程的用户态内存空间。实际上我们同一份文件内容相当于读了两次，先读入内核空间，再从内核空间读入用户空间。

对于mmap的内存映射，是将物理内存映射到进程的虚拟地址空间中去，那么进程对文件的访问就相当于直接对内存的访问，从而加快了读写操作的效率。
1、mmap是在磁盘上建立一个文件，每个进程地址空间中开辟出一块空间进行映射。
而对于shm而言，shm每个进程最终会映射到同一块物理内存。shm保存在物理内存，这样读写的速度要比磁盘要快，但是存储量不是特别大。
2、相对于shm来说，mmap更加简单，调用更加方便，所以这也是大家都喜欢用的原因。
3、另外mmap有一个好处是当机器重启，因为mmap把文件保存在磁盘上，这个文件还保存了操作系统同步的映像，所以mmap不会丢失，但是shmget就会丢失。

==============================================================================

指令周期 :取出并执行一条指令的时间。 

机器周期 :又称CPU周期，CPU访问一次内存所花的时间较长，因此用从内存读取一条指令字的最短时间来定义。

时钟周期: 通常称为节拍脉冲或T周期。处理操作的最基本单位，即CPU主频。

三者的关系：指令周期通常用若干个机器周期表示，而机器周期又包含若干个时钟周期。

例题：CPU周期也称为机器周期，一般是从内存中（A）的最短时间。
A。读一个指令　　　　　　B。写一个指令
C。读写一个指令　　　　　D。执行一个指令

==============================================================================

GDB可以同时调试多个程序。
只需要设置follow-fork-mode(默认值：parent)和detach-on-fork（默认值：on）即可。
follow-fork-mode detach-on-fork 说明：
parent                   on               只调试主进程（GDB默认）
child                    on               只调试子进程
parent                   off              同时调试两个进程，gdb跟主进程，子进程block在fork位置
child                    off              同时调试两个进程，gdb跟子进程，主进程block在fork位置

info inferiors
显示GDB调试的所有inferior，GDB会为他们分配ID。其中带有*的进程是正在调试的inferior。（ GDB将每一个被调试程序的执行状态记录在一个名为inferior的结构中。一般情况下一个inferior对应一个进程，每个不同的inferior有不同的地址空间。

切换调试的进程：inferior <infer number>

detach inferior detach掉编号是infno的inferior。注意这个inferior还存在，可以再次用run命令执行它。
kill inferior infno kill掉infno号inferior。注意这个inferior仍然存在，可以再次用run等命令执行它

set schedule-multiple on|off 
设为off:只有当前inferior会执行。 
设为on：全部是执行状态的inferior都会执行。 
这个选项类似于多线程调试里的set

info threads 显示可以调试的所有线程。gdb会为每个线程分配一个ID（和tid不同），编号一般从1开始。后面的ID是指这个ID
thread ID 切换当前调试的线程为指定ID的线程。 

thread apply ID1 ID2 IDN command: 
让线程编号是ID1，ID2…等等的线程都执行command命令。

thread apply all command：所有线程都执行command命令。

set scheduler-locking off|on|step： 
在调式某一个线程时，其他线程是否执行。在使用step或continue命令调试当前被调试线程的时候，其他线程也是同时执行的，
如果我们只想要被调试的线程执行，而其他线程停止等待，那就要锁定要调试的线程，只让他运行。
off:不锁定任何线程，默认值。 
on:锁定其他线程，只有当前线程执行。
step:在step（单步）时，只有被调试线程运行。

gdb基本命令：
next 
这样，执行一行代码，如果是函数也会跳过函数。这个命令可以简化为n. 

step 
这样，也会执行一行代码，不过如果遇到函数的话就会进入函数的内部，再一行一行的执行。 

finish 
这里，运行程序，直到当前函数运行完毕返回再停止。例如进入的单步执行如果已经进入了某函数，而想退出该函数返回到它的调用函数中，可使用命令finish. 

return 
这样，将会忽略当前函数还没有执行完毕的语句，强制返回。return后面可以接一个表达式，表达式的返回值就是函数的返回值。 

break 46 if testsize==100 
这里，如果testsize==100就在46行处断点。 

call func 强制调用函数

==============================================================================
SWAP分区
CPU处理的数据是来自内存的，不与硬盘直接打交道，所有数据都要经过内存来处理，最后输出到硬盘中去，而内存往往容量有限，有些时候程序需要的数据要高于内存的容量，这自然就会造成计算机运行的速度很慢，swap相当于是用硬盘来延伸内存的记录空间。如果硬件的配备足够的话，swap不会被用到，只有内存不足时才会将内存中暂时不用的数据年搬到swap中去，空出来的内存给程序使用。

==============================================================================
编写service文件
1、主程序 main 里，在开头加入语句。

2、编写service脚本 /etc/init.d/myservice：
. /etc/init.d/functions
SNAME=myservice
WORKPATH=/home/work/myservice
PROG="$WORKPATH/$SNAME"
RETVAL=0
# start function
start()
#stop function
stop()

3、提升脚本文件权限
chmod +x /etc/init.d/myservice

4、将service 加入到系统自启动列表；
chkconfig --add /etc/init.d/myservice
这里常常会出现 service myservice does not support chkconfig 问题，添加下面两句到 #!/bin/bash 之后。
# chkconfig: 2345 10 90 
# description: myservice ....
其中2345是默认启动级别，级别有0-6共7个级别。

　　等级0表示：表示关机 　　

　　等级1表示：单用户模式 　　

　　等级2表示：无网络连接的多用户命令行模式 　　

　　等级3表示：有网络连接的多用户命令行模式 　　

　　等级4表示：不可用 　　

　　等级5表示：带图形界面的多用户模式 　　

　　等级6表示：重新启动

10是启动优先级，90是停止优先级，优先级范围是0－100，数字越大，优先级越低。

5、如果主程序有其他依赖库文件，将依赖库到路径加入到  /etc/ld.so.conf 文件里；

==============================================================================

POSIX信号量有三种操作：

（1）创建一个信号量。创建的过程还要求初始化信号量的值。

根据信号量取值（代表可用资源的数目）的不同，POSIX信号量还可以分为：

二值信号量：信号量的值只有0和1，这和互斥量很类型，若资源被锁住，信号量的值为0，若资源可用，则信号量的值为1；
计数信号量：信号量的值在0到一个大于1的限制值（POSIX指出系统的最大限制值至少要为32767）。该计数表示可用的资源的个数。
（2）等待一个信号量（wait）。该操作会检查信号量的值，如果其值小于或等于0，那就阻塞，直到该值变成大于0，然后等待进程将信号量的值减1，进程获得共享资源的访问权限。这整个操作必须是一个原子操作。该操作还经常被称为P操作（荷兰语Proberen，意为：尝试）。

（3）挂出一个信号量（post）。该操作将信号量的值加1，如果有进程阻塞着等待该信号量，那么其中一个进程将被唤醒。该操作也必须是一个原子操作。该操作还经常被称为V操作（荷兰语Verhogen，意为：增加）

//信号量的初始化  
get = 0;//表示可读资源的数目  
put = 1;//表示可写资源的数目  
  
//生产者进程                               //消费者进程  
for(; ;){                                    for(; ;){  
Sem_wait(put);                                 Sem_wait(get);  
写共享缓冲区；                               读共享缓冲区；  
Sem_post(get);                                 Sem_post(put);  
}                                           }
==============================================================================

线程安全性
mutex
条件变量
死锁
race condition
false sharing
多线程debug调试
生产者消费者模型

==============================================================================

